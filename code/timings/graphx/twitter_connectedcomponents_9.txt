21/10/27 15:18:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:18:03 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:18:04 INFO ResourceUtils: ==============================================================
21/10/27 15:18:04 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:18:04 INFO ResourceUtils: ==============================================================
21/10/27 15:18:04 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:18:04 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:18:04 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:18:04 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:18:04 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:18:04 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:18:04 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:18:04 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:18:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:18:04 INFO Utils: Successfully started service 'sparkDriver' on port 46634.
21/10/27 15:18:04 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:18:04 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:18:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:18:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:18:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:18:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ac583850-e472-450d-b3b5-239f26b41406
21/10/27 15:18:04 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:18:04 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:18:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:18:04 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:18:04 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:46634/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635340683982
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:18:05 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 50 ms (0 ms spent in bootstraps)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027151805-0000
21/10/27 15:18:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43558.
21/10/27 15:18:05 INFO NettyBlockTransferService: Server created on node030.ib.cluster:43558
21/10/27 15:18:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:18:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 43558, None)
21/10/27 15:18:05 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:43558 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 43558, None)
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027151805-0000/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:18:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 43558, None)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027151805-0000/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027151805-0000/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027151805-0000/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027151805-0000/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:18:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 43558, None)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027151805-0000/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027151805-0000/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027151805-0000/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027151805-0000/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027151805-0000/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027151805-0000/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027151805-0000/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027151805-0000/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027151805-0000/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027151805-0000/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027151805-0000/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027151805-0000/0 is now RUNNING
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027151805-0000/2 is now RUNNING
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027151805-0000/7 is now RUNNING
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027151805-0000/6 is now RUNNING
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027151805-0000/1 is now RUNNING
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027151805-0000/3 is now RUNNING
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027151805-0000/5 is now RUNNING
21/10/27 15:18:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027151805-0000/4 is now RUNNING
21/10/27 15:18:05 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m12.244s
user	2m38.867s
sys	0m21.096s
21/10/27 15:22:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:22:16 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:22:16 INFO ResourceUtils: ==============================================================
21/10/27 15:22:16 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:22:16 INFO ResourceUtils: ==============================================================
21/10/27 15:22:16 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:22:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:22:16 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:22:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:22:16 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:22:16 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:22:16 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:22:16 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:22:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:22:16 INFO Utils: Successfully started service 'sparkDriver' on port 43711.
21/10/27 15:22:16 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:22:16 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:22:16 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:22:16 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:22:16 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:22:16 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1479c734-f665-4048-a59b-2313f03ce724
21/10/27 15:22:16 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:22:16 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:22:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:22:17 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:22:17 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:43711/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635340936258
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:22:17 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 46 ms (0 ms spent in bootstraps)
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027152217-0001
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152217-0001/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152217-0001/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152217-0001/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152217-0001/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152217-0001/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152217-0001/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152217-0001/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152217-0001/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152217-0001/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152217-0001/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152217-0001/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:22:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44724.
21/10/27 15:22:17 INFO NettyBlockTransferService: Server created on node030.ib.cluster:44724
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152217-0001/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152217-0001/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152217-0001/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152217-0001/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:22:17 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:22:17 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152217-0001/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:22:17 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 44724, None)
21/10/27 15:22:17 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:44724 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 44724, None)
21/10/27 15:22:17 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 44724, None)
21/10/27 15:22:17 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 44724, None)
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152217-0001/0 is now RUNNING
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152217-0001/4 is now RUNNING
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152217-0001/7 is now RUNNING
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152217-0001/5 is now RUNNING
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152217-0001/3 is now RUNNING
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152217-0001/2 is now RUNNING
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152217-0001/1 is now RUNNING
21/10/27 15:22:17 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152217-0001/6 is now RUNNING
21/10/27 15:22:18 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m6.166s
user	2m36.437s
sys	0m21.962s
21/10/27 15:26:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:26:22 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:26:22 INFO ResourceUtils: ==============================================================
21/10/27 15:26:22 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:26:22 INFO ResourceUtils: ==============================================================
21/10/27 15:26:22 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:26:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:26:22 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:26:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:26:22 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:26:22 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:26:22 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:26:22 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:26:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:26:22 INFO Utils: Successfully started service 'sparkDriver' on port 44144.
21/10/27 15:26:22 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:26:22 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:26:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:26:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:26:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:26:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-60adad71-68d9-4951-9787-f0d5a59fd492
21/10/27 15:26:22 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:26:23 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:26:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:26:23 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:26:23 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:44144/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635341182385
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:26:23 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 57 ms (0 ms spent in bootstraps)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027152623-0002
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152623-0002/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152623-0002/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152623-0002/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152623-0002/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152623-0002/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152623-0002/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152623-0002/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152623-0002/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152623-0002/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152623-0002/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152623-0002/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152623-0002/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152623-0002/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152623-0002/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027152623-0002/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027152623-0002/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:26:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36591.
21/10/27 15:26:23 INFO NettyBlockTransferService: Server created on node030.ib.cluster:36591
21/10/27 15:26:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:26:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 36591, None)
21/10/27 15:26:23 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:36591 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 36591, None)
21/10/27 15:26:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 36591, None)
21/10/27 15:26:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 36591, None)
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152623-0002/0 is now RUNNING
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152623-0002/2 is now RUNNING
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152623-0002/1 is now RUNNING
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152623-0002/5 is now RUNNING
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152623-0002/3 is now RUNNING
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152623-0002/4 is now RUNNING
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152623-0002/6 is now RUNNING
21/10/27 15:26:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027152623-0002/7 is now RUNNING
21/10/27 15:26:23 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230
21/10/27 15:30:26 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /10.149.0.34:35536 is closed
java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@4be7292f rejected from java.util.concurrent.ThreadPoolExecutor@1e5d980e[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 2947]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1379)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at org.apache.spark.util.ThreadUtils$$anon$1.execute(ThreadUtils.scala:99)
	at scala.concurrent.impl.ExecutionContextImpl$$anon$4.execute(ExecutionContextImpl.scala:138)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.complete(Promise.scala:53)
	at scala.concurrent.Promise.complete$(Promise.scala:52)
	at scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:187)
	at scala.concurrent.impl.Promise.$anonfun$transform$1(Promise.scala:33)
	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64)
	at scala.concurrent.BatchingExecutor$Batch.processBatch$1(BatchingExecutor.scala:67)
	at scala.concurrent.BatchingExecutor$Batch.$anonfun$run$1(BatchingExecutor.scala:82)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85)
	at scala.concurrent.BatchingExecutor$Batch.run(BatchingExecutor.scala:59)
	at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:875)
	at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:110)
	at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:107)
	at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:873)
	at scala.concurrent.impl.CallbackRunnable.executeWithValue(Promise.scala:72)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.$anonfun$tryComplete$1$adapted(Promise.scala:288)
	at scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:288)
	at scala.concurrent.Promise.tryFailure(Promise.scala:112)
	at scala.concurrent.Promise.tryFailure$(Promise.scala:112)
	at scala.concurrent.impl.Promise$DefaultPromise.tryFailure(Promise.scala:187)
	at org.apache.spark.rpc.netty.NettyRpcEnv.org$apache$spark$rpc$netty$NettyRpcEnv$$onFailure$1(NettyRpcEnv.scala:214)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.NettyRpcEnv.$anonfun$askAbortable$6$adapted(NettyRpcEnv.scala:245)
	at org.apache.spark.rpc.netty.RpcOutboxMessage.onFailure(Outbox.scala:86)
	at org.apache.spark.network.client.TransportResponseHandler.failOutstandingRequests(TransportResponseHandler.java:118)
	at org.apache.spark.network.client.TransportResponseHandler.channelInactive(TransportResponseHandler.java:147)
	at org.apache.spark.network.server.TransportChannelHandler.channelInactive(TransportChannelHandler.java:117)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at io.netty.handler.timeout.IdleStateHandler.channelInactive(IdleStateHandler.java:277)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.ChannelInboundHandlerAdapter.channelInactive(ChannelInboundHandlerAdapter.java:81)
	at org.apache.spark.network.util.TransportFrameDecoder.channelInactive(TransportFrameDecoder.java:225)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelInactive(AbstractChannelHandlerContext.java:241)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelInactive(DefaultChannelPipeline.java:1405)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:262)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelInactive(AbstractChannelHandlerContext.java:248)
	at io.netty.channel.DefaultChannelPipeline.fireChannelInactive(DefaultChannelPipeline.java:901)
	at io.netty.channel.AbstractChannel$AbstractUnsafe$8.run(AbstractChannel.java:831)
	at io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:164)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasksFrom(SingleThreadEventExecutor.java:425)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:374)
	at io.netty.util.concurrent.SingleThreadEventExecutor.confirmShutdown(SingleThreadEventExecutor.java:760)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:527)
	at io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:986)
	at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
	at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
	at java.lang.Thread.run(Thread.java:748)

real	4m6.360s
user	2m34.070s
sys	0m22.324s
21/10/27 15:30:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:30:28 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:30:28 INFO ResourceUtils: ==============================================================
21/10/27 15:30:28 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:30:28 INFO ResourceUtils: ==============================================================
21/10/27 15:30:28 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:30:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:30:28 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:30:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:30:28 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:30:28 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:30:28 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:30:28 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:30:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:30:29 INFO Utils: Successfully started service 'sparkDriver' on port 38823.
21/10/27 15:30:29 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:30:29 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:30:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:30:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:30:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:30:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3e699f88-0b6d-4aee-ae7c-e81dbcf827e9
21/10/27 15:30:29 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:30:29 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:30:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:30:29 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:30:29 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:38823/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635341428760
21/10/27 15:30:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:30:30 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 57 ms (0 ms spent in bootstraps)
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027153030-0003
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153030-0003/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153030-0003/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153030-0003/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153030-0003/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153030-0003/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153030-0003/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153030-0003/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153030-0003/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153030-0003/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153030-0003/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153030-0003/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153030-0003/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153030-0003/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:30:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34211.
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153030-0003/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:30:30 INFO NettyBlockTransferService: Server created on node030.ib.cluster:34211
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153030-0003/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153030-0003/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:30:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:30:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 34211, None)
21/10/27 15:30:30 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:34211 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 34211, None)
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153030-0003/0 is now RUNNING
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153030-0003/7 is now RUNNING
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153030-0003/5 is now RUNNING
21/10/27 15:30:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 34211, None)
21/10/27 15:30:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 34211, None)
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153030-0003/4 is now RUNNING
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153030-0003/2 is now RUNNING
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153030-0003/3 is now RUNNING
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153030-0003/1 is now RUNNING
21/10/27 15:30:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153030-0003/6 is now RUNNING
21/10/27 15:30:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m10.793s
user	2m37.365s
sys	0m21.405s
21/10/27 15:34:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:34:39 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:34:39 INFO ResourceUtils: ==============================================================
21/10/27 15:34:39 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:34:39 INFO ResourceUtils: ==============================================================
21/10/27 15:34:39 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:34:39 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:34:39 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:34:39 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:34:39 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:34:39 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:34:39 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:34:39 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:34:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:34:40 INFO Utils: Successfully started service 'sparkDriver' on port 35493.
21/10/27 15:34:40 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:34:40 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:34:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:34:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:34:40 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:34:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0e018de3-23bd-4906-8df2-155f9353701e
21/10/27 15:34:40 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:34:40 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:34:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:34:40 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:34:40 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:35493/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635341679566
21/10/27 15:34:40 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:34:40 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 59 ms (0 ms spent in bootstraps)
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027153441-0004
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153441-0004/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153441-0004/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153441-0004/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153441-0004/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153441-0004/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153441-0004/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153441-0004/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153441-0004/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153441-0004/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153441-0004/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153441-0004/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:34:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37827.
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153441-0004/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:34:41 INFO NettyBlockTransferService: Server created on node030.ib.cluster:37827
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153441-0004/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153441-0004/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153441-0004/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153441-0004/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:34:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:34:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 37827, None)
21/10/27 15:34:41 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:37827 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 37827, None)
21/10/27 15:34:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 37827, None)
21/10/27 15:34:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 37827, None)
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153441-0004/0 is now RUNNING
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153441-0004/2 is now RUNNING
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153441-0004/1 is now RUNNING
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153441-0004/3 is now RUNNING
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153441-0004/7 is now RUNNING
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153441-0004/6 is now RUNNING
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153441-0004/4 is now RUNNING
21/10/27 15:34:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153441-0004/5 is now RUNNING
21/10/27 15:34:41 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m7.849s
user	2m32.571s
sys	0m21.080s
21/10/27 15:38:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:38:47 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:38:47 INFO ResourceUtils: ==============================================================
21/10/27 15:38:47 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:38:47 INFO ResourceUtils: ==============================================================
21/10/27 15:38:47 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:38:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:38:47 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:38:47 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:38:47 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:38:47 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:38:47 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:38:47 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:38:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:38:47 INFO Utils: Successfully started service 'sparkDriver' on port 38640.
21/10/27 15:38:47 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:38:48 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:38:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:38:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:38:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:38:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ad2f1e99-1443-4b6c-ba8f-b8bbc8c8d707
21/10/27 15:38:48 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:38:48 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:38:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:38:48 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:38:48 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:38640/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635341927437
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:38:48 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 57 ms (0 ms spent in bootstraps)
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027153848-0005
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153848-0005/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153848-0005/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153848-0005/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153848-0005/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153848-0005/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153848-0005/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153848-0005/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153848-0005/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153848-0005/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:38:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42374.
21/10/27 15:38:48 INFO NettyBlockTransferService: Server created on node030.ib.cluster:42374
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153848-0005/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153848-0005/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153848-0005/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153848-0005/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153848-0005/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:38:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027153848-0005/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:38:48 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027153848-0005/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:38:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 42374, None)
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153848-0005/3 is now RUNNING
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153848-0005/0 is now RUNNING
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153848-0005/2 is now RUNNING
21/10/27 15:38:48 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:42374 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 42374, None)
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153848-0005/5 is now RUNNING
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153848-0005/4 is now RUNNING
21/10/27 15:38:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 42374, None)
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153848-0005/6 is now RUNNING
21/10/27 15:38:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 42374, None)
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153848-0005/7 is now RUNNING
21/10/27 15:38:48 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027153848-0005/1 is now RUNNING
21/10/27 15:38:49 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m14.812s
user	2m33.779s
sys	0m20.146s
21/10/27 15:43:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:43:02 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:43:02 INFO ResourceUtils: ==============================================================
21/10/27 15:43:02 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:43:02 INFO ResourceUtils: ==============================================================
21/10/27 15:43:02 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:43:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:43:02 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:43:02 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:43:02 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:43:02 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:43:02 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:43:02 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:43:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:43:02 INFO Utils: Successfully started service 'sparkDriver' on port 35025.
21/10/27 15:43:02 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:43:02 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:43:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:43:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:43:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:43:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-08f247d8-fda2-42bb-8c16-cc5a6e3374e6
21/10/27 15:43:02 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:43:02 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:43:03 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:43:03 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:43:03 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:35025/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635342182237
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:43:03 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 52 ms (0 ms spent in bootstraps)
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027154303-0006
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154303-0006/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154303-0006/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154303-0006/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154303-0006/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154303-0006/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154303-0006/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154303-0006/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154303-0006/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154303-0006/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:43:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36682.
21/10/27 15:43:03 INFO NettyBlockTransferService: Server created on node030.ib.cluster:36682
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154303-0006/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154303-0006/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154303-0006/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154303-0006/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154303-0006/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154303-0006/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:43:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154303-0006/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:43:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 36682, None)
21/10/27 15:43:03 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:36682 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 36682, None)
21/10/27 15:43:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 36682, None)
21/10/27 15:43:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 36682, None)
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154303-0006/0 is now RUNNING
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154303-0006/1 is now RUNNING
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154303-0006/4 is now RUNNING
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154303-0006/2 is now RUNNING
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154303-0006/7 is now RUNNING
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154303-0006/5 is now RUNNING
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154303-0006/3 is now RUNNING
21/10/27 15:43:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154303-0006/6 is now RUNNING
21/10/27 15:43:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m4.145s
user	2m37.497s
sys	0m21.726s
21/10/27 15:47:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:47:06 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:47:06 INFO ResourceUtils: ==============================================================
21/10/27 15:47:06 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:47:06 INFO ResourceUtils: ==============================================================
21/10/27 15:47:06 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:47:06 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:47:06 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:47:06 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:47:06 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:47:06 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:47:06 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:47:06 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:47:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:47:06 INFO Utils: Successfully started service 'sparkDriver' on port 41213.
21/10/27 15:47:06 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:47:07 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:47:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:47:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:47:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:47:07 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6dfd5159-1c78-4bcf-8d69-1a0551a6e300
21/10/27 15:47:07 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:47:07 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:47:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:47:07 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:47:07 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:41213/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635342426436
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:47:07 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027154707-0007
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154707-0007/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154707-0007/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154707-0007/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154707-0007/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154707-0007/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154707-0007/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154707-0007/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154707-0007/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154707-0007/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154707-0007/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154707-0007/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154707-0007/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154707-0007/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154707-0007/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:47:07 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42101.
21/10/27 15:47:07 INFO NettyBlockTransferService: Server created on node030.ib.cluster:42101
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027154707-0007/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:47:07 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:47:07 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027154707-0007/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:47:07 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 42101, None)
21/10/27 15:47:07 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:42101 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 42101, None)
21/10/27 15:47:07 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 42101, None)
21/10/27 15:47:07 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 42101, None)
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154707-0007/1 is now RUNNING
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154707-0007/7 is now RUNNING
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154707-0007/4 is now RUNNING
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154707-0007/6 is now RUNNING
21/10/27 15:47:07 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154707-0007/0 is now RUNNING
21/10/27 15:47:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154707-0007/2 is now RUNNING
21/10/27 15:47:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154707-0007/5 is now RUNNING
21/10/27 15:47:08 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027154707-0007/3 is now RUNNING
21/10/27 15:47:08 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m14.150s
user	2m37.051s
sys	0m19.558s
21/10/27 15:51:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:51:20 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:51:20 INFO ResourceUtils: ==============================================================
21/10/27 15:51:20 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:51:20 INFO ResourceUtils: ==============================================================
21/10/27 15:51:20 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:51:20 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:51:20 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:51:20 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:51:20 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:51:20 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:51:20 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:51:20 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:51:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:51:21 INFO Utils: Successfully started service 'sparkDriver' on port 39603.
21/10/27 15:51:21 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:51:21 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:51:21 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:51:21 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:51:21 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:51:21 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-6e778148-7e5f-428f-b1ff-3f42d82db776
21/10/27 15:51:21 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:51:21 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:51:21 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:51:21 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:51:21 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:39603/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635342680634
21/10/27 15:51:21 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:51:21 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 52 ms (0 ms spent in bootstraps)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027155122-0008
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155122-0008/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155122-0008/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155122-0008/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155122-0008/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155122-0008/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155122-0008/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155122-0008/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155122-0008/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155122-0008/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155122-0008/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155122-0008/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155122-0008/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155122-0008/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155122-0008/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:51:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36321.
21/10/27 15:51:22 INFO NettyBlockTransferService: Server created on node030.ib.cluster:36321
21/10/27 15:51:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155122-0008/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155122-0008/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:51:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 36321, None)
21/10/27 15:51:22 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:36321 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 36321, None)
21/10/27 15:51:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 36321, None)
21/10/27 15:51:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 36321, None)
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155122-0008/5 is now RUNNING
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155122-0008/0 is now RUNNING
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155122-0008/6 is now RUNNING
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155122-0008/2 is now RUNNING
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155122-0008/3 is now RUNNING
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155122-0008/4 is now RUNNING
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155122-0008/7 is now RUNNING
21/10/27 15:51:22 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155122-0008/1 is now RUNNING
21/10/27 15:51:22 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m3.657s
user	2m35.892s
sys	0m22.754s
21/10/27 15:55:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:55:24 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:55:24 INFO ResourceUtils: ==============================================================
21/10/27 15:55:24 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:55:24 INFO ResourceUtils: ==============================================================
21/10/27 15:55:24 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:55:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:55:24 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:55:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:55:24 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:55:24 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:55:24 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:55:24 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:55:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:55:24 INFO Utils: Successfully started service 'sparkDriver' on port 46535.
21/10/27 15:55:24 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:55:24 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:55:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:55:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:55:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:55:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-1c9dc096-a10f-42a9-8799-e690bac29e2b
21/10/27 15:55:24 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:55:24 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:55:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:55:25 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:55:25 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:46535/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635342924248
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:55:25 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 59 ms (0 ms spent in bootstraps)
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027155525-0009
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155525-0009/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155525-0009/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155525-0009/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155525-0009/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155525-0009/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155525-0009/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155525-0009/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155525-0009/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155525-0009/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155525-0009/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155525-0009/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:55:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40679.
21/10/27 15:55:25 INFO NettyBlockTransferService: Server created on node030.ib.cluster:40679
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155525-0009/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155525-0009/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155525-0009/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155525-0009/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155525-0009/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:55:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:55:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 40679, None)
21/10/27 15:55:25 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:40679 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 40679, None)
21/10/27 15:55:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 40679, None)
21/10/27 15:55:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 40679, None)
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155525-0009/6 is now RUNNING
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155525-0009/2 is now RUNNING
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155525-0009/4 is now RUNNING
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155525-0009/1 is now RUNNING
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155525-0009/0 is now RUNNING
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155525-0009/3 is now RUNNING
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155525-0009/7 is now RUNNING
21/10/27 15:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155525-0009/5 is now RUNNING
21/10/27 15:55:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m9.480s
user	2m32.972s
sys	0m22.035s
21/10/27 15:59:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 15:59:33 INFO SparkContext: Running Spark version 3.2.0
21/10/27 15:59:33 INFO ResourceUtils: ==============================================================
21/10/27 15:59:33 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 15:59:33 INFO ResourceUtils: ==============================================================
21/10/27 15:59:33 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 15:59:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 15:59:33 INFO ResourceProfile: Limiting resource is cpu
21/10/27 15:59:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 15:59:33 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 15:59:33 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 15:59:33 INFO SecurityManager: Changing view acls groups to: 
21/10/27 15:59:33 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 15:59:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 15:59:34 INFO Utils: Successfully started service 'sparkDriver' on port 34712.
21/10/27 15:59:34 INFO SparkEnv: Registering MapOutputTracker
21/10/27 15:59:34 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 15:59:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 15:59:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 15:59:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 15:59:34 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c3006e51-8ce5-486b-8c36-cbebe5e96e1e
21/10/27 15:59:34 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 15:59:34 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 15:59:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 15:59:34 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 15:59:34 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:34712/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635343173750
21/10/27 15:59:34 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 15:59:35 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027155935-0010
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155935-0010/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155935-0010/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155935-0010/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155935-0010/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155935-0010/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 15:59:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44080.
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155935-0010/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 15:59:35 INFO NettyBlockTransferService: Server created on node030.ib.cluster:44080
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155935-0010/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155935-0010/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155935-0010/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 15:59:35 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155935-0010/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155935-0010/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155935-0010/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155935-0010/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155935-0010/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027155935-0010/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027155935-0010/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 15:59:35 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 44080, None)
21/10/27 15:59:35 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:44080 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 44080, None)
21/10/27 15:59:35 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 44080, None)
21/10/27 15:59:35 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 44080, None)
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155935-0010/1 is now RUNNING
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155935-0010/5 is now RUNNING
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155935-0010/7 is now RUNNING
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155935-0010/6 is now RUNNING
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155935-0010/0 is now RUNNING
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155935-0010/2 is now RUNNING
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155935-0010/4 is now RUNNING
21/10/27 15:59:35 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027155935-0010/3 is now RUNNING
21/10/27 15:59:35 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m3.469s
user	2m33.543s
sys	0m21.644s
21/10/27 16:03:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:03:37 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:03:37 INFO ResourceUtils: ==============================================================
21/10/27 16:03:37 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:03:37 INFO ResourceUtils: ==============================================================
21/10/27 16:03:37 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:03:37 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:03:37 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:03:37 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:03:37 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:03:37 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:03:37 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:03:37 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:03:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:03:37 INFO Utils: Successfully started service 'sparkDriver' on port 43210.
21/10/27 16:03:37 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:03:37 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:03:37 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:03:37 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:03:37 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:03:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-19c7460a-6fde-48cd-b6b2-becf94bc6923
21/10/27 16:03:37 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:03:37 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:03:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:03:38 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:03:38 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:43210/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635343417184
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:03:38 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 55 ms (0 ms spent in bootstraps)
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027160338-0011
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160338-0011/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160338-0011/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160338-0011/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160338-0011/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160338-0011/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160338-0011/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160338-0011/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160338-0011/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160338-0011/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160338-0011/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160338-0011/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160338-0011/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160338-0011/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160338-0011/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:03:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37676.
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160338-0011/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:03:38 INFO NettyBlockTransferService: Server created on node030.ib.cluster:37676
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160338-0011/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:03:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:03:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 37676, None)
21/10/27 16:03:38 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:37676 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 37676, None)
21/10/27 16:03:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 37676, None)
21/10/27 16:03:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 37676, None)
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160338-0011/0 is now RUNNING
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160338-0011/3 is now RUNNING
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160338-0011/1 is now RUNNING
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160338-0011/2 is now RUNNING
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160338-0011/7 is now RUNNING
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160338-0011/4 is now RUNNING
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160338-0011/5 is now RUNNING
21/10/27 16:03:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160338-0011/6 is now RUNNING
21/10/27 16:03:38 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m3.441s
user	2m43.743s
sys	0m20.045s
21/10/27 16:07:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:07:40 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:07:40 INFO ResourceUtils: ==============================================================
21/10/27 16:07:40 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:07:40 INFO ResourceUtils: ==============================================================
21/10/27 16:07:40 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:07:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:07:40 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:07:40 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:07:40 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:07:40 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:07:40 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:07:40 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:07:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:07:41 INFO Utils: Successfully started service 'sparkDriver' on port 38248.
21/10/27 16:07:41 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:07:41 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:07:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:07:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:07:41 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:07:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-0824cad5-9dfe-49c5-a9ba-11359cba208e
21/10/27 16:07:41 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:07:41 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:07:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:07:41 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:07:41 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:38248/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635343660609
21/10/27 16:07:41 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:07:41 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 59 ms (0 ms spent in bootstraps)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027160742-0012
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160742-0012/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160742-0012/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160742-0012/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160742-0012/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160742-0012/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160742-0012/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160742-0012/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160742-0012/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160742-0012/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160742-0012/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160742-0012/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160742-0012/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160742-0012/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160742-0012/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:07:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42033.
21/10/27 16:07:42 INFO NettyBlockTransferService: Server created on node030.ib.cluster:42033
21/10/27 16:07:42 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027160742-0012/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027160742-0012/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:07:42 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 42033, None)
21/10/27 16:07:42 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:42033 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 42033, None)
21/10/27 16:07:42 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 42033, None)
21/10/27 16:07:42 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 42033, None)
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160742-0012/0 is now RUNNING
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160742-0012/4 is now RUNNING
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160742-0012/6 is now RUNNING
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160742-0012/7 is now RUNNING
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160742-0012/2 is now RUNNING
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160742-0012/5 is now RUNNING
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160742-0012/1 is now RUNNING
21/10/27 16:07:42 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027160742-0012/3 is now RUNNING
21/10/27 16:07:42 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m7.708s
user	2m33.874s
sys	0m22.373s
21/10/27 16:11:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:11:48 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:11:48 INFO ResourceUtils: ==============================================================
21/10/27 16:11:48 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:11:48 INFO ResourceUtils: ==============================================================
21/10/27 16:11:48 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:11:48 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:11:48 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:11:48 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:11:48 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:11:48 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:11:48 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:11:48 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:11:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:11:48 INFO Utils: Successfully started service 'sparkDriver' on port 42960.
21/10/27 16:11:48 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:11:48 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:11:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:11:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:11:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:11:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7cc64602-0074-4c8f-9e87-7cbae7b11b04
21/10/27 16:11:48 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:11:48 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:11:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:11:49 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:11:49 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:42960/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635343908255
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:11:49 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 46 ms (0 ms spent in bootstraps)
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027161149-0013
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161149-0013/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161149-0013/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161149-0013/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161149-0013/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161149-0013/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161149-0013/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161149-0013/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161149-0013/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161149-0013/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:11:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36157.
21/10/27 16:11:49 INFO NettyBlockTransferService: Server created on node030.ib.cluster:36157
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161149-0013/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161149-0013/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161149-0013/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161149-0013/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:11:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161149-0013/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161149-0013/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161149-0013/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:11:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 36157, None)
21/10/27 16:11:49 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:36157 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 36157, None)
21/10/27 16:11:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 36157, None)
21/10/27 16:11:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 36157, None)
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161149-0013/2 is now RUNNING
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161149-0013/6 is now RUNNING
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161149-0013/0 is now RUNNING
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161149-0013/1 is now RUNNING
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161149-0013/5 is now RUNNING
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161149-0013/7 is now RUNNING
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161149-0013/4 is now RUNNING
21/10/27 16:11:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161149-0013/3 is now RUNNING
21/10/27 16:11:49 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m6.951s
user	2m42.345s
sys	0m19.886s
21/10/27 16:15:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:15:55 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:15:55 INFO ResourceUtils: ==============================================================
21/10/27 16:15:55 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:15:55 INFO ResourceUtils: ==============================================================
21/10/27 16:15:55 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:15:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:15:55 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:15:55 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:15:55 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:15:55 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:15:55 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:15:55 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:15:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:15:55 INFO Utils: Successfully started service 'sparkDriver' on port 42250.
21/10/27 16:15:55 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:15:55 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:15:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:15:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:15:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:15:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-b2f1e991-1c53-4fc1-9e39-0c58f8547614
21/10/27 16:15:55 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:15:55 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:15:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:15:56 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:15:56 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:42250/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635344155283
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:15:56 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 59 ms (0 ms spent in bootstraps)
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027161556-0014
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161556-0014/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161556-0014/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161556-0014/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161556-0014/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161556-0014/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161556-0014/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161556-0014/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161556-0014/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161556-0014/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161556-0014/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161556-0014/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:15:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36089.
21/10/27 16:15:56 INFO NettyBlockTransferService: Server created on node030.ib.cluster:36089
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161556-0014/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161556-0014/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161556-0014/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:15:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161556-0014/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:15:56 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161556-0014/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:15:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 36089, None)
21/10/27 16:15:56 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:36089 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 36089, None)
21/10/27 16:15:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 36089, None)
21/10/27 16:15:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 36089, None)
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161556-0014/0 is now RUNNING
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161556-0014/2 is now RUNNING
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161556-0014/7 is now RUNNING
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161556-0014/1 is now RUNNING
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161556-0014/6 is now RUNNING
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161556-0014/5 is now RUNNING
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161556-0014/4 is now RUNNING
21/10/27 16:15:56 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161556-0014/3 is now RUNNING
21/10/27 16:15:57 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m3.029s
user	2m32.698s
sys	0m22.236s
21/10/27 16:19:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:19:58 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:19:58 INFO ResourceUtils: ==============================================================
21/10/27 16:19:58 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:19:58 INFO ResourceUtils: ==============================================================
21/10/27 16:19:58 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:19:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:19:58 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:19:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:19:58 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:19:58 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:19:58 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:19:58 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:19:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:19:58 INFO Utils: Successfully started service 'sparkDriver' on port 45102.
21/10/27 16:19:58 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:19:58 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:19:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:19:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:19:59 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:19:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-47c27fac-1a68-47d1-ba84-26f99a7633ed
21/10/27 16:19:59 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:19:59 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:19:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:19:59 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:19:59 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:45102/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635344398395
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:19:59 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 58 ms (0 ms spent in bootstraps)
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027161959-0015
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161959-0015/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161959-0015/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161959-0015/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161959-0015/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161959-0015/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161959-0015/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161959-0015/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161959-0015/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161959-0015/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161959-0015/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161959-0015/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:19:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44862.
21/10/27 16:19:59 INFO NettyBlockTransferService: Server created on node030.ib.cluster:44862
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161959-0015/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161959-0015/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161959-0015/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:19:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027161959-0015/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:19:59 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027161959-0015/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:19:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 44862, None)
21/10/27 16:19:59 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:44862 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 44862, None)
21/10/27 16:19:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 44862, None)
21/10/27 16:19:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 44862, None)
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161959-0015/0 is now RUNNING
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161959-0015/5 is now RUNNING
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161959-0015/2 is now RUNNING
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161959-0015/6 is now RUNNING
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161959-0015/7 is now RUNNING
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161959-0015/4 is now RUNNING
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161959-0015/1 is now RUNNING
21/10/27 16:19:59 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027161959-0015/3 is now RUNNING
21/10/27 16:20:00 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m13.016s
user	2m38.803s
sys	0m20.254s
21/10/27 16:24:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:24:11 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:24:11 INFO ResourceUtils: ==============================================================
21/10/27 16:24:11 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:24:11 INFO ResourceUtils: ==============================================================
21/10/27 16:24:11 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:24:11 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:24:11 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:24:11 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:24:11 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:24:11 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:24:11 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:24:11 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:24:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:24:11 INFO Utils: Successfully started service 'sparkDriver' on port 33033.
21/10/27 16:24:11 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:24:11 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:24:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:24:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:24:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:24:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f7d26bae-3c69-4df5-97c4-5c8ea648ec36
21/10/27 16:24:12 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:24:12 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:24:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:24:12 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:24:12 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:33033/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635344651365
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:24:12 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 57 ms (0 ms spent in bootstraps)
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027162412-0016
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162412-0016/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162412-0016/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162412-0016/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162412-0016/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162412-0016/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162412-0016/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162412-0016/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:24:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37373.
21/10/27 16:24:12 INFO NettyBlockTransferService: Server created on node030.ib.cluster:37373
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162412-0016/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162412-0016/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162412-0016/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162412-0016/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:24:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162412-0016/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162412-0016/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162412-0016/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162412-0016/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162412-0016/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:24:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 37373, None)
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162412-0016/0 is now RUNNING
21/10/27 16:24:12 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:37373 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 37373, None)
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162412-0016/4 is now RUNNING
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162412-0016/2 is now RUNNING
21/10/27 16:24:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 37373, None)
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162412-0016/7 is now RUNNING
21/10/27 16:24:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 37373, None)
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162412-0016/6 is now RUNNING
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162412-0016/5 is now RUNNING
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162412-0016/1 is now RUNNING
21/10/27 16:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162412-0016/3 is now RUNNING
21/10/27 16:24:13 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m5.360s
user	2m31.821s
sys	0m22.079s
21/10/27 16:28:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:28:16 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:28:16 INFO ResourceUtils: ==============================================================
21/10/27 16:28:16 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:28:16 INFO ResourceUtils: ==============================================================
21/10/27 16:28:16 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:28:16 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:28:16 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:28:16 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:28:16 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:28:16 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:28:16 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:28:16 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:28:16 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:28:17 INFO Utils: Successfully started service 'sparkDriver' on port 36319.
21/10/27 16:28:17 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:28:17 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:28:17 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:28:17 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:28:17 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:28:17 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-029dda3a-1ba0-426d-b1ea-52262b76bfed
21/10/27 16:28:17 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:28:17 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:28:17 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:28:17 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:28:17 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:36319/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635344896713
21/10/27 16:28:17 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:28:17 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 57 ms (0 ms spent in bootstraps)
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027162818-0017
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162818-0017/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162818-0017/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162818-0017/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162818-0017/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162818-0017/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162818-0017/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162818-0017/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162818-0017/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162818-0017/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162818-0017/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162818-0017/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:28:18 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39960.
21/10/27 16:28:18 INFO NettyBlockTransferService: Server created on node030.ib.cluster:39960
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162818-0017/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162818-0017/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162818-0017/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:28:18 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027162818-0017/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027162818-0017/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:28:18 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 39960, None)
21/10/27 16:28:18 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:39960 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 39960, None)
21/10/27 16:28:18 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 39960, None)
21/10/27 16:28:18 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 39960, None)
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162818-0017/2 is now RUNNING
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162818-0017/7 is now RUNNING
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162818-0017/5 is now RUNNING
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162818-0017/4 is now RUNNING
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162818-0017/1 is now RUNNING
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162818-0017/3 is now RUNNING
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162818-0017/0 is now RUNNING
21/10/27 16:28:18 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027162818-0017/6 is now RUNNING
21/10/27 16:28:18 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m7.168s
user	2m33.730s
sys	0m22.046s
21/10/27 16:32:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:32:23 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:32:23 INFO ResourceUtils: ==============================================================
21/10/27 16:32:23 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:32:23 INFO ResourceUtils: ==============================================================
21/10/27 16:32:23 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:32:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:32:24 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:32:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:32:24 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:32:24 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:32:24 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:32:24 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:32:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:32:24 INFO Utils: Successfully started service 'sparkDriver' on port 39737.
21/10/27 16:32:24 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:32:24 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:32:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:32:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:32:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:32:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-564d4f83-7c7d-460a-a3ca-d1d669a66c97
21/10/27 16:32:24 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:32:24 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:32:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:32:24 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:32:24 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:39737/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635345143920
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:32:25 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027163225-0018
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163225-0018/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163225-0018/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163225-0018/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163225-0018/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163225-0018/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163225-0018/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163225-0018/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163225-0018/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163225-0018/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163225-0018/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163225-0018/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163225-0018/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163225-0018/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163225-0018/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:32:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33721.
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163225-0018/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:32:25 INFO NettyBlockTransferService: Server created on node030.ib.cluster:33721
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163225-0018/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:32:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:32:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 33721, None)
21/10/27 16:32:25 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:33721 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 33721, None)
21/10/27 16:32:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 33721, None)
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163225-0018/2 is now RUNNING
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163225-0018/5 is now RUNNING
21/10/27 16:32:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 33721, None)
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163225-0018/0 is now RUNNING
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163225-0018/3 is now RUNNING
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163225-0018/1 is now RUNNING
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163225-0018/7 is now RUNNING
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163225-0018/6 is now RUNNING
21/10/27 16:32:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163225-0018/4 is now RUNNING
21/10/27 16:32:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m2.142s
user	2m36.254s
sys	0m21.073s
21/10/27 16:36:25 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:36:26 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:36:26 INFO ResourceUtils: ==============================================================
21/10/27 16:36:26 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:36:26 INFO ResourceUtils: ==============================================================
21/10/27 16:36:26 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:36:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:36:26 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:36:26 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:36:26 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:36:26 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:36:26 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:36:26 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:36:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:36:26 INFO Utils: Successfully started service 'sparkDriver' on port 35058.
21/10/27 16:36:26 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:36:26 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:36:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:36:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:36:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:36:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2489c6d8-b74a-455b-b72d-d3ee17c62237
21/10/27 16:36:26 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:36:26 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:36:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:36:27 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:36:27 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:35058/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635345385996
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:36:27 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 61 ms (0 ms spent in bootstraps)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027163627-0019
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163627-0019/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163627-0019/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163627-0019/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163627-0019/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163627-0019/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163627-0019/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163627-0019/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163627-0019/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163627-0019/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163627-0019/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163627-0019/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163627-0019/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163627-0019/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163627-0019/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:36:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38958.
21/10/27 16:36:27 INFO NettyBlockTransferService: Server created on node030.ib.cluster:38958
21/10/27 16:36:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027163627-0019/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027163627-0019/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:36:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 38958, None)
21/10/27 16:36:27 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:38958 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 38958, None)
21/10/27 16:36:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 38958, None)
21/10/27 16:36:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 38958, None)
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163627-0019/1 is now RUNNING
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163627-0019/2 is now RUNNING
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163627-0019/6 is now RUNNING
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163627-0019/0 is now RUNNING
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163627-0019/5 is now RUNNING
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163627-0019/7 is now RUNNING
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163627-0019/3 is now RUNNING
21/10/27 16:36:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027163627-0019/4 is now RUNNING
21/10/27 16:36:27 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m14.190s
user	2m36.385s
sys	0m20.893s
21/10/27 16:40:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:40:40 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:40:40 INFO ResourceUtils: ==============================================================
21/10/27 16:40:40 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:40:40 INFO ResourceUtils: ==============================================================
21/10/27 16:40:40 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:40:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:40:40 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:40:40 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:40:40 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:40:40 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:40:40 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:40:40 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:40:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:40:40 INFO Utils: Successfully started service 'sparkDriver' on port 33188.
21/10/27 16:40:40 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:40:40 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:40:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:40:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:40:40 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:40:40 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-77d94f86-b34e-485c-9f74-cf103db865bd
21/10/27 16:40:40 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:40:40 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:40:41 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:40:41 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:40:41 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:33188/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635345640265
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:40:41 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 61 ms (0 ms spent in bootstraps)
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027164041-0020
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164041-0020/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164041-0020/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164041-0020/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164041-0020/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164041-0020/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164041-0020/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164041-0020/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164041-0020/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164041-0020/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:40:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36903.
21/10/27 16:40:41 INFO NettyBlockTransferService: Server created on node030.ib.cluster:36903
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164041-0020/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164041-0020/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164041-0020/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164041-0020/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:40:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164041-0020/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164041-0020/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:40:41 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164041-0020/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:40:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 36903, None)
21/10/27 16:40:41 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:36903 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 36903, None)
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164041-0020/2 is now RUNNING
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164041-0020/0 is now RUNNING
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164041-0020/1 is now RUNNING
21/10/27 16:40:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 36903, None)
21/10/27 16:40:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 36903, None)
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164041-0020/5 is now RUNNING
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164041-0020/3 is now RUNNING
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164041-0020/6 is now RUNNING
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164041-0020/7 is now RUNNING
21/10/27 16:40:41 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164041-0020/4 is now RUNNING
21/10/27 16:40:42 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m3.876s
user	2m39.325s
sys	0m21.709s
21/10/27 16:44:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:44:44 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:44:44 INFO ResourceUtils: ==============================================================
21/10/27 16:44:44 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:44:44 INFO ResourceUtils: ==============================================================
21/10/27 16:44:44 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:44:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:44:44 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:44:44 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:44:44 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:44:44 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:44:44 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:44:44 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:44:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:44:44 INFO Utils: Successfully started service 'sparkDriver' on port 45350.
21/10/27 16:44:44 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:44:44 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:44:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:44:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:44:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:44:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a850efd2-7153-45bb-ad9d-bd980c5d530c
21/10/27 16:44:44 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:44:44 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:44:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:44:45 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:44:45 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:45350/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635345884099
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:44:45 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 45 ms (0 ms spent in bootstraps)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027164445-0021
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164445-0021/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164445-0021/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164445-0021/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164445-0021/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164445-0021/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164445-0021/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164445-0021/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164445-0021/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164445-0021/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164445-0021/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164445-0021/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164445-0021/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164445-0021/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164445-0021/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:44:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42448.
21/10/27 16:44:45 INFO NettyBlockTransferService: Server created on node030.ib.cluster:42448
21/10/27 16:44:45 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164445-0021/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164445-0021/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:44:45 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 42448, None)
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164445-0021/5 is now RUNNING
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164445-0021/6 is now RUNNING
21/10/27 16:44:45 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:42448 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 42448, None)
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164445-0021/0 is now RUNNING
21/10/27 16:44:45 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 42448, None)
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164445-0021/1 is now RUNNING
21/10/27 16:44:45 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 42448, None)
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164445-0021/3 is now RUNNING
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164445-0021/2 is now RUNNING
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164445-0021/7 is now RUNNING
21/10/27 16:44:45 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164445-0021/4 is now RUNNING
21/10/27 16:44:45 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m0.762s
user	2m27.798s
sys	0m21.712s
21/10/27 16:48:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:48:45 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:48:45 INFO ResourceUtils: ==============================================================
21/10/27 16:48:45 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:48:45 INFO ResourceUtils: ==============================================================
21/10/27 16:48:45 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:48:45 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:48:45 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:48:45 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:48:45 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:48:45 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:48:45 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:48:45 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:48:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:48:45 INFO Utils: Successfully started service 'sparkDriver' on port 43683.
21/10/27 16:48:45 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:48:45 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:48:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:48:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:48:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:48:45 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f2b698d5-1d7f-40a9-a984-2724d12e76d9
21/10/27 16:48:45 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:48:45 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:48:45 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:48:46 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:48:46 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:43683/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635346124997
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:48:46 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027164846-0022
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164846-0022/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164846-0022/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164846-0022/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164846-0022/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164846-0022/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164846-0022/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164846-0022/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164846-0022/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164846-0022/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164846-0022/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164846-0022/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164846-0022/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164846-0022/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164846-0022/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:48:46 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43178.
21/10/27 16:48:46 INFO NettyBlockTransferService: Server created on node030.ib.cluster:43178
21/10/27 16:48:46 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027164846-0022/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027164846-0022/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:48:46 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 43178, None)
21/10/27 16:48:46 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:43178 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 43178, None)
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164846-0022/3 is now RUNNING
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164846-0022/2 is now RUNNING
21/10/27 16:48:46 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 43178, None)
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164846-0022/7 is now RUNNING
21/10/27 16:48:46 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 43178, None)
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164846-0022/1 is now RUNNING
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164846-0022/5 is now RUNNING
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164846-0022/0 is now RUNNING
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164846-0022/6 is now RUNNING
21/10/27 16:48:46 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027164846-0022/4 is now RUNNING
21/10/27 16:48:46 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m7.616s
user	2m36.406s
sys	0m21.130s
21/10/27 16:52:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:52:52 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:52:52 INFO ResourceUtils: ==============================================================
21/10/27 16:52:52 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:52:52 INFO ResourceUtils: ==============================================================
21/10/27 16:52:52 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:52:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:52:52 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:52:52 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:52:52 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:52:52 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:52:52 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:52:52 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:52:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:52:53 INFO Utils: Successfully started service 'sparkDriver' on port 45910.
21/10/27 16:52:53 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:52:53 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:52:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:52:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:52:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:52:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9073027e-21ed-4075-a772-66ad90ee3fbd
21/10/27 16:52:53 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:52:53 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:52:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:52:53 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:52:53 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:45910/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635346372567
21/10/27 16:52:53 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:52:53 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 58 ms (0 ms spent in bootstraps)
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027165254-0023
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165254-0023/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165254-0023/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165254-0023/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165254-0023/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165254-0023/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165254-0023/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165254-0023/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165254-0023/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165254-0023/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165254-0023/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165254-0023/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165254-0023/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165254-0023/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:52:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39546.
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165254-0023/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:52:54 INFO NettyBlockTransferService: Server created on node030.ib.cluster:39546
21/10/27 16:52:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165254-0023/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165254-0023/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:52:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 39546, None)
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165254-0023/0 is now RUNNING
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165254-0023/6 is now RUNNING
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165254-0023/1 is now RUNNING
21/10/27 16:52:54 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:39546 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 39546, None)
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165254-0023/5 is now RUNNING
21/10/27 16:52:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 39546, None)
21/10/27 16:52:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 39546, None)
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165254-0023/3 is now RUNNING
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165254-0023/2 is now RUNNING
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165254-0023/7 is now RUNNING
21/10/27 16:52:54 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165254-0023/4 is now RUNNING
21/10/27 16:52:54 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m3.399s
user	2m32.304s
sys	0m21.380s
21/10/27 16:56:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 16:56:55 INFO SparkContext: Running Spark version 3.2.0
21/10/27 16:56:56 INFO ResourceUtils: ==============================================================
21/10/27 16:56:56 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 16:56:56 INFO ResourceUtils: ==============================================================
21/10/27 16:56:56 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 16:56:56 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 16:56:56 INFO ResourceProfile: Limiting resource is cpu
21/10/27 16:56:56 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 16:56:56 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 16:56:56 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 16:56:56 INFO SecurityManager: Changing view acls groups to: 
21/10/27 16:56:56 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 16:56:56 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 16:56:56 INFO Utils: Successfully started service 'sparkDriver' on port 44601.
21/10/27 16:56:56 INFO SparkEnv: Registering MapOutputTracker
21/10/27 16:56:56 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 16:56:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 16:56:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 16:56:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 16:56:56 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-dad42f49-9f21-44b1-ae39-447e42c8958c
21/10/27 16:56:56 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 16:56:56 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 16:56:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 16:56:56 INFO SparkUI: Bound SparkUI to node030.ib.cluster, and started at http://node030.ib.cluster:4040
21/10/27 16:56:57 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010_map/target/scala-2.12/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar at spark://node030.ib.cluster:44601/jars/graphx_connected_components_twitter_2010_map_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635346615984
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.30:7077...
21/10/27 16:56:57 INFO TransportClientFactory: Successfully created connection to /10.149.0.30:7077 after 53 ms (0 ms spent in bootstraps)
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027165657-0024
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165657-0024/0 on worker-20211027151801-10.149.0.32-41009 (10.149.0.32:41009) with 32 core(s)
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165657-0024/0 on hostPort 10.149.0.32:41009 with 32 core(s), 60.0 GiB RAM
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165657-0024/1 on worker-20211027151800-10.149.0.35-37115 (10.149.0.35:37115) with 32 core(s)
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165657-0024/1 on hostPort 10.149.0.35:37115 with 32 core(s), 60.0 GiB RAM
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165657-0024/2 on worker-20211027151800-10.149.0.38-36053 (10.149.0.38:36053) with 32 core(s)
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165657-0024/2 on hostPort 10.149.0.38:36053 with 32 core(s), 60.0 GiB RAM
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165657-0024/3 on worker-20211027151800-10.149.0.36-34513 (10.149.0.36:34513) with 32 core(s)
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165657-0024/3 on hostPort 10.149.0.36:34513 with 32 core(s), 60.0 GiB RAM
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165657-0024/4 on worker-20211027151800-10.149.0.33-37063 (10.149.0.33:37063) with 32 core(s)
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165657-0024/4 on hostPort 10.149.0.33:37063 with 32 core(s), 60.0 GiB RAM
21/10/27 16:56:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42734.
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165657-0024/5 on worker-20211027151800-10.149.0.31-34568 (10.149.0.31:34568) with 32 core(s)
21/10/27 16:56:57 INFO NettyBlockTransferService: Server created on node030.ib.cluster:42734
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165657-0024/5 on hostPort 10.149.0.31:34568 with 32 core(s), 60.0 GiB RAM
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165657-0024/6 on worker-20211027151800-10.149.0.34-43413 (10.149.0.34:43413) with 32 core(s)
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165657-0024/6 on hostPort 10.149.0.34:43413 with 32 core(s), 60.0 GiB RAM
21/10/27 16:56:57 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027165657-0024/7 on worker-20211027151759-10.149.0.37-41652 (10.149.0.37:41652) with 32 core(s)
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027165657-0024/7 on hostPort 10.149.0.37:41652 with 32 core(s), 60.0 GiB RAM
21/10/27 16:56:57 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node030.ib.cluster, 42734, None)
21/10/27 16:56:57 INFO BlockManagerMasterEndpoint: Registering block manager node030.ib.cluster:42734 with 398.7 MiB RAM, BlockManagerId(driver, node030.ib.cluster, 42734, None)
21/10/27 16:56:57 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node030.ib.cluster, 42734, None)
21/10/27 16:56:57 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node030.ib.cluster, 42734, None)
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165657-0024/2 is now RUNNING
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165657-0024/5 is now RUNNING
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165657-0024/7 is now RUNNING
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165657-0024/3 is now RUNNING
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165657-0024/0 is now RUNNING
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165657-0024/6 is now RUNNING
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165657-0024/4 is now RUNNING
21/10/27 16:56:57 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027165657-0024/1 is now RUNNING
21/10/27 16:56:57 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
41652230

real	4m5.941s
user	2m35.588s
sys	0m21.890s
