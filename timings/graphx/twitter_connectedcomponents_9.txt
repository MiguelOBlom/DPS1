21/10/27 11:35:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 11:35:01 INFO SparkContext: Running Spark version 3.2.0
21/10/27 11:35:01 INFO ResourceUtils: ==============================================================
21/10/27 11:35:01 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 11:35:01 INFO ResourceUtils: ==============================================================
21/10/27 11:35:01 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 11:35:01 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 11:35:01 INFO ResourceProfile: Limiting resource is cpu
21/10/27 11:35:01 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 11:35:01 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 11:35:01 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 11:35:01 INFO SecurityManager: Changing view acls groups to: 
21/10/27 11:35:01 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 11:35:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 11:35:02 INFO Utils: Successfully started service 'sparkDriver' on port 36244.
21/10/27 11:35:02 INFO SparkEnv: Registering MapOutputTracker
21/10/27 11:35:02 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 11:35:02 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 11:35:02 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 11:35:02 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 11:35:02 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-88cfdbf8-7505-4add-ba1c-84c716f14e7f
21/10/27 11:35:02 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 11:35:02 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 11:35:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 11:35:02 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 11:35:02 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:36244/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635327301803
21/10/27 11:35:02 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 11:35:03 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027113503-0000
21/10/27 11:35:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34869.
21/10/27 11:35:03 INFO NettyBlockTransferService: Server created on node054.ib.cluster:34869
21/10/27 11:35:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 11:35:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 34869, None)
21/10/27 11:35:03 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:34869 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 34869, None)
21/10/27 11:35:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 34869, None)
21/10/27 11:35:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 34869, None)
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113503-0000/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113503-0000/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113503-0000/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113503-0000/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113503-0000/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113503-0000/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113503-0000/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113503-0000/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113503-0000/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113503-0000/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113503-0000/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113503-0000/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113503-0000/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113503-0000/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113503-0000/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113503-0000/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113503-0000/1 is now RUNNING
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113503-0000/0 is now RUNNING
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113503-0000/2 is now RUNNING
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113503-0000/3 is now RUNNING
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113503-0000/5 is now RUNNING
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113503-0000/7 is now RUNNING
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113503-0000/6 is now RUNNING
21/10/27 11:35:03 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113503-0000/4 is now RUNNING
21/10/27 11:35:03 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m3.559s
user	2m32.311s
sys	0m19.990s
21/10/27 11:39:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 11:39:05 INFO SparkContext: Running Spark version 3.2.0
21/10/27 11:39:05 INFO ResourceUtils: ==============================================================
21/10/27 11:39:05 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 11:39:05 INFO ResourceUtils: ==============================================================
21/10/27 11:39:05 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 11:39:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 11:39:05 INFO ResourceProfile: Limiting resource is cpu
21/10/27 11:39:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 11:39:05 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 11:39:05 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 11:39:05 INFO SecurityManager: Changing view acls groups to: 
21/10/27 11:39:05 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 11:39:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 11:39:05 INFO Utils: Successfully started service 'sparkDriver' on port 37842.
21/10/27 11:39:05 INFO SparkEnv: Registering MapOutputTracker
21/10/27 11:39:05 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 11:39:05 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 11:39:05 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 11:39:05 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 11:39:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2a92b86d-ea73-4c43-ad3b-56c0a7922ff1
21/10/27 11:39:06 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 11:39:06 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 11:39:06 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 11:39:06 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 11:39:06 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:37842/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635327545449
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 11:39:06 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 51 ms (0 ms spent in bootstraps)
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027113906-0001
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113906-0001/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113906-0001/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113906-0001/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113906-0001/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113906-0001/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113906-0001/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113906-0001/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113906-0001/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113906-0001/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113906-0001/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113906-0001/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113906-0001/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113906-0001/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113906-0001/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027113906-0001/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 11:39:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38154.
21/10/27 11:39:06 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027113906-0001/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 11:39:06 INFO NettyBlockTransferService: Server created on node054.ib.cluster:38154
21/10/27 11:39:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 11:39:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 38154, None)
21/10/27 11:39:06 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:38154 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 38154, None)
21/10/27 11:39:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 38154, None)
21/10/27 11:39:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 38154, None)
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113906-0001/6 is now RUNNING
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113906-0001/4 is now RUNNING
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113906-0001/0 is now RUNNING
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113906-0001/7 is now RUNNING
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113906-0001/1 is now RUNNING
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113906-0001/2 is now RUNNING
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113906-0001/3 is now RUNNING
21/10/27 11:39:06 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027113906-0001/5 is now RUNNING
21/10/27 11:39:07 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	3m58.382s
user	2m36.441s
sys	0m19.605s
21/10/27 11:43:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 11:43:03 INFO SparkContext: Running Spark version 3.2.0
21/10/27 11:43:04 INFO ResourceUtils: ==============================================================
21/10/27 11:43:04 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 11:43:04 INFO ResourceUtils: ==============================================================
21/10/27 11:43:04 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 11:43:04 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 11:43:04 INFO ResourceProfile: Limiting resource is cpu
21/10/27 11:43:04 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 11:43:04 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 11:43:04 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 11:43:04 INFO SecurityManager: Changing view acls groups to: 
21/10/27 11:43:04 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 11:43:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 11:43:04 INFO Utils: Successfully started service 'sparkDriver' on port 44389.
21/10/27 11:43:04 INFO SparkEnv: Registering MapOutputTracker
21/10/27 11:43:04 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 11:43:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 11:43:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 11:43:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 11:43:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ce3ebfb0-6da4-48f0-b204-dbb5f4a9b621
21/10/27 11:43:04 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 11:43:04 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 11:43:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 11:43:04 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 11:43:04 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:44389/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635327783974
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 11:43:05 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 49 ms (0 ms spent in bootstraps)
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027114305-0002
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114305-0002/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114305-0002/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114305-0002/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114305-0002/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114305-0002/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114305-0002/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114305-0002/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114305-0002/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114305-0002/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114305-0002/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114305-0002/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 11:43:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33739.
21/10/27 11:43:05 INFO NettyBlockTransferService: Server created on node054.ib.cluster:33739
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114305-0002/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114305-0002/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114305-0002/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114305-0002/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114305-0002/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 11:43:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 11:43:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 33739, None)
21/10/27 11:43:05 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:33739 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 33739, None)
21/10/27 11:43:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 33739, None)
21/10/27 11:43:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 33739, None)
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114305-0002/1 is now RUNNING
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114305-0002/6 is now RUNNING
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114305-0002/4 is now RUNNING
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114305-0002/0 is now RUNNING
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114305-0002/3 is now RUNNING
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114305-0002/2 is now RUNNING
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114305-0002/5 is now RUNNING
21/10/27 11:43:05 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114305-0002/7 is now RUNNING
21/10/27 11:43:05 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m6.979s
user	2m26.034s
sys	0m20.036s
21/10/27 11:47:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 11:47:11 INFO SparkContext: Running Spark version 3.2.0
21/10/27 11:47:11 INFO ResourceUtils: ==============================================================
21/10/27 11:47:11 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 11:47:11 INFO ResourceUtils: ==============================================================
21/10/27 11:47:11 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 11:47:11 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 11:47:11 INFO ResourceProfile: Limiting resource is cpu
21/10/27 11:47:11 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 11:47:11 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 11:47:11 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 11:47:11 INFO SecurityManager: Changing view acls groups to: 
21/10/27 11:47:11 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 11:47:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 11:47:11 INFO Utils: Successfully started service 'sparkDriver' on port 34283.
21/10/27 11:47:11 INFO SparkEnv: Registering MapOutputTracker
21/10/27 11:47:11 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 11:47:11 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 11:47:11 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 11:47:11 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 11:47:11 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-878f134a-187f-4868-929a-f7efebb2c713
21/10/27 11:47:11 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 11:47:11 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 11:47:11 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 11:47:12 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 11:47:12 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:34283/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635328031019
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 11:47:12 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027114712-0003
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114712-0003/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114712-0003/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114712-0003/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114712-0003/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114712-0003/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114712-0003/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114712-0003/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114712-0003/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114712-0003/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114712-0003/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114712-0003/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114712-0003/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114712-0003/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 11:47:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40663.
21/10/27 11:47:12 INFO NettyBlockTransferService: Server created on node054.ib.cluster:40663
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114712-0003/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027114712-0003/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027114712-0003/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 11:47:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 11:47:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 40663, None)
21/10/27 11:47:12 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:40663 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 40663, None)
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114712-0003/6 is now RUNNING
21/10/27 11:47:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 40663, None)
21/10/27 11:47:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 40663, None)
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114712-0003/2 is now RUNNING
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114712-0003/3 is now RUNNING
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114712-0003/4 is now RUNNING
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114712-0003/1 is now RUNNING
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114712-0003/0 is now RUNNING
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114712-0003/5 is now RUNNING
21/10/27 11:47:12 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027114712-0003/7 is now RUNNING
21/10/27 11:47:12 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m8.860s
user	2m34.695s
sys	0m19.781s
21/10/27 11:51:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 11:51:19 INFO SparkContext: Running Spark version 3.2.0
21/10/27 11:51:19 INFO ResourceUtils: ==============================================================
21/10/27 11:51:19 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 11:51:19 INFO ResourceUtils: ==============================================================
21/10/27 11:51:19 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 11:51:19 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 11:51:19 INFO ResourceProfile: Limiting resource is cpu
21/10/27 11:51:19 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 11:51:19 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 11:51:19 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 11:51:19 INFO SecurityManager: Changing view acls groups to: 
21/10/27 11:51:19 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 11:51:19 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 11:51:20 INFO Utils: Successfully started service 'sparkDriver' on port 38852.
21/10/27 11:51:20 INFO SparkEnv: Registering MapOutputTracker
21/10/27 11:51:20 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 11:51:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 11:51:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 11:51:20 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 11:51:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ab0e08dc-782f-4770-9aff-4535445a9bed
21/10/27 11:51:20 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 11:51:20 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 11:51:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 11:51:20 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 11:51:20 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:38852/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635328279668
21/10/27 11:51:20 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 11:51:20 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 46 ms (0 ms spent in bootstraps)
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027115121-0004
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115121-0004/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115121-0004/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115121-0004/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115121-0004/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 11:51:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39127.
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115121-0004/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 11:51:21 INFO NettyBlockTransferService: Server created on node054.ib.cluster:39127
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115121-0004/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115121-0004/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115121-0004/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115121-0004/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 11:51:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115121-0004/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115121-0004/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115121-0004/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115121-0004/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115121-0004/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115121-0004/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115121-0004/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 11:51:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 39127, None)
21/10/27 11:51:21 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:39127 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 39127, None)
21/10/27 11:51:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 39127, None)
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115121-0004/0 is now RUNNING
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115121-0004/3 is now RUNNING
21/10/27 11:51:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 39127, None)
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115121-0004/2 is now RUNNING
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115121-0004/1 is now RUNNING
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115121-0004/5 is now RUNNING
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115121-0004/4 is now RUNNING
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115121-0004/7 is now RUNNING
21/10/27 11:51:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115121-0004/6 is now RUNNING
21/10/27 11:51:21 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m3.985s
user	2m35.447s
sys	0m19.427s
21/10/27 11:55:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 11:55:23 INFO SparkContext: Running Spark version 3.2.0
21/10/27 11:55:23 INFO ResourceUtils: ==============================================================
21/10/27 11:55:23 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 11:55:23 INFO ResourceUtils: ==============================================================
21/10/27 11:55:23 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 11:55:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 11:55:23 INFO ResourceProfile: Limiting resource is cpu
21/10/27 11:55:23 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 11:55:23 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 11:55:23 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 11:55:23 INFO SecurityManager: Changing view acls groups to: 
21/10/27 11:55:23 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 11:55:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 11:55:24 INFO Utils: Successfully started service 'sparkDriver' on port 34601.
21/10/27 11:55:24 INFO SparkEnv: Registering MapOutputTracker
21/10/27 11:55:24 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 11:55:24 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 11:55:24 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 11:55:24 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 11:55:24 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c691ee70-a3f2-472e-8317-9b21b030ed51
21/10/27 11:55:24 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 11:55:24 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 11:55:24 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 11:55:24 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 11:55:24 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:34601/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635328523663
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 11:55:24 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 57 ms (0 ms spent in bootstraps)
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027115524-0005
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115524-0005/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115524-0005/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115524-0005/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115524-0005/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115524-0005/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 11:55:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44260.
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115524-0005/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 11:55:24 INFO NettyBlockTransferService: Server created on node054.ib.cluster:44260
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115524-0005/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115524-0005/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115524-0005/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115524-0005/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 11:55:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115524-0005/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115524-0005/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115524-0005/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115524-0005/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115524-0005/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 11:55:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115524-0005/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 11:55:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 44260, None)
21/10/27 11:55:24 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:44260 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 44260, None)
21/10/27 11:55:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 44260, None)
21/10/27 11:55:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 44260, None)
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115524-0005/1 is now RUNNING
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115524-0005/4 is now RUNNING
21/10/27 11:55:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115524-0005/0 is now RUNNING
21/10/27 11:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115524-0005/5 is now RUNNING
21/10/27 11:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115524-0005/6 is now RUNNING
21/10/27 11:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115524-0005/7 is now RUNNING
21/10/27 11:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115524-0005/2 is now RUNNING
21/10/27 11:55:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115524-0005/3 is now RUNNING
21/10/27 11:55:25 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	3m58.165s
user	2m38.776s
sys	0m19.842s
21/10/27 11:59:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 11:59:21 INFO SparkContext: Running Spark version 3.2.0
21/10/27 11:59:21 INFO ResourceUtils: ==============================================================
21/10/27 11:59:21 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 11:59:21 INFO ResourceUtils: ==============================================================
21/10/27 11:59:21 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 11:59:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 11:59:22 INFO ResourceProfile: Limiting resource is cpu
21/10/27 11:59:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 11:59:22 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 11:59:22 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 11:59:22 INFO SecurityManager: Changing view acls groups to: 
21/10/27 11:59:22 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 11:59:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 11:59:22 INFO Utils: Successfully started service 'sparkDriver' on port 46536.
21/10/27 11:59:22 INFO SparkEnv: Registering MapOutputTracker
21/10/27 11:59:22 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 11:59:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 11:59:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 11:59:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 11:59:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ad791e0b-9cb4-407b-ad79-9de325aa1388
21/10/27 11:59:22 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 11:59:22 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 11:59:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 11:59:22 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 11:59:22 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:46536/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635328761913
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 11:59:23 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 61 ms (0 ms spent in bootstraps)
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027115923-0006
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115923-0006/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115923-0006/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115923-0006/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115923-0006/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115923-0006/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 11:59:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46269.
21/10/27 11:59:23 INFO NettyBlockTransferService: Server created on node054.ib.cluster:46269
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115923-0006/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115923-0006/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115923-0006/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115923-0006/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 11:59:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115923-0006/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115923-0006/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115923-0006/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115923-0006/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115923-0006/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027115923-0006/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027115923-0006/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 11:59:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 46269, None)
21/10/27 11:59:23 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:46269 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 46269, None)
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115923-0006/6 is now RUNNING
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115923-0006/2 is now RUNNING
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115923-0006/1 is now RUNNING
21/10/27 11:59:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 46269, None)
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115923-0006/3 is now RUNNING
21/10/27 11:59:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 46269, None)
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115923-0006/4 is now RUNNING
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115923-0006/0 is now RUNNING
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115923-0006/7 is now RUNNING
21/10/27 11:59:23 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027115923-0006/5 is now RUNNING
21/10/27 11:59:23 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m2.440s
user	2m36.225s
sys	0m19.165s
21/10/27 12:03:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:03:24 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:03:24 INFO ResourceUtils: ==============================================================
21/10/27 12:03:24 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:03:24 INFO ResourceUtils: ==============================================================
21/10/27 12:03:24 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:03:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:03:24 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:03:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:03:24 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:03:24 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:03:24 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:03:24 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:03:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:03:24 INFO Utils: Successfully started service 'sparkDriver' on port 42914.
21/10/27 12:03:24 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:03:24 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:03:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:03:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:03:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:03:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-432659c4-f60b-4e45-9cd8-650599cd311b
21/10/27 12:03:25 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:03:25 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:03:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:03:25 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:03:25 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:42914/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635329004469
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:03:25 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027120325-0007
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120325-0007/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120325-0007/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120325-0007/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120325-0007/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120325-0007/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120325-0007/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120325-0007/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120325-0007/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:03:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38651.
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120325-0007/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:03:25 INFO NettyBlockTransferService: Server created on node054.ib.cluster:38651
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120325-0007/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120325-0007/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120325-0007/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120325-0007/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:03:25 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120325-0007/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120325-0007/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:03:25 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120325-0007/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:03:25 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 38651, None)
21/10/27 12:03:25 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:38651 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 38651, None)
21/10/27 12:03:25 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 38651, None)
21/10/27 12:03:25 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 38651, None)
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120325-0007/5 is now RUNNING
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120325-0007/6 is now RUNNING
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120325-0007/2 is now RUNNING
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120325-0007/7 is now RUNNING
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120325-0007/4 is now RUNNING
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120325-0007/0 is now RUNNING
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120325-0007/3 is now RUNNING
21/10/27 12:03:25 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120325-0007/1 is now RUNNING
21/10/27 12:03:26 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m0.552s
user	2m32.780s
sys	0m19.582s
21/10/27 12:07:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:07:25 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:07:25 INFO ResourceUtils: ==============================================================
21/10/27 12:07:25 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:07:25 INFO ResourceUtils: ==============================================================
21/10/27 12:07:25 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:07:25 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:07:25 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:07:25 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:07:25 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:07:25 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:07:25 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:07:25 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:07:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:07:25 INFO Utils: Successfully started service 'sparkDriver' on port 38432.
21/10/27 12:07:25 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:07:25 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:07:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:07:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:07:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:07:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-f7e7e2cc-51ac-447f-a635-483a62eb59f1
21/10/27 12:07:25 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:07:25 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:07:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:07:26 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:07:26 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:38432/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635329245079
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:07:26 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027120726-0008
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120726-0008/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120726-0008/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120726-0008/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120726-0008/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120726-0008/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120726-0008/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120726-0008/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120726-0008/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120726-0008/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120726-0008/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120726-0008/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120726-0008/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120726-0008/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:07:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42816.
21/10/27 12:07:26 INFO NettyBlockTransferService: Server created on node054.ib.cluster:42816
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120726-0008/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027120726-0008/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:07:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027120726-0008/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:07:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 42816, None)
21/10/27 12:07:26 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:42816 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 42816, None)
21/10/27 12:07:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 42816, None)
21/10/27 12:07:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 42816, None)
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120726-0008/4 is now RUNNING
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120726-0008/3 is now RUNNING
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120726-0008/0 is now RUNNING
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120726-0008/2 is now RUNNING
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120726-0008/7 is now RUNNING
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120726-0008/1 is now RUNNING
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120726-0008/5 is now RUNNING
21/10/27 12:07:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027120726-0008/6 is now RUNNING
21/10/27 12:07:26 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	3m59.571s
user	2m33.595s
sys	0m19.372s
21/10/27 12:11:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:11:24 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:11:24 INFO ResourceUtils: ==============================================================
21/10/27 12:11:24 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:11:24 INFO ResourceUtils: ==============================================================
21/10/27 12:11:24 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:11:24 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:11:24 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:11:24 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:11:24 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:11:24 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:11:24 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:11:24 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:11:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:11:25 INFO Utils: Successfully started service 'sparkDriver' on port 39085.
21/10/27 12:11:25 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:11:25 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:11:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:11:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:11:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:11:25 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-51e65aed-3d8a-47b2-a3b0-a631d7983b60
21/10/27 12:11:25 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:11:25 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:11:25 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:11:25 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:11:25 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:39085/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635329484651
21/10/27 12:11:25 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:11:25 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 59 ms (0 ms spent in bootstraps)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027121126-0009
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121126-0009/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121126-0009/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121126-0009/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121126-0009/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121126-0009/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121126-0009/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121126-0009/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121126-0009/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121126-0009/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121126-0009/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:11:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33665.
21/10/27 12:11:26 INFO NettyBlockTransferService: Server created on node054.ib.cluster:33665
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121126-0009/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121126-0009/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121126-0009/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121126-0009/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121126-0009/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121126-0009/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:11:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:11:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 33665, None)
21/10/27 12:11:26 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:33665 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 33665, None)
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121126-0009/3 is now RUNNING
21/10/27 12:11:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 33665, None)
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121126-0009/1 is now RUNNING
21/10/27 12:11:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 33665, None)
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121126-0009/2 is now RUNNING
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121126-0009/7 is now RUNNING
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121126-0009/5 is now RUNNING
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121126-0009/4 is now RUNNING
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121126-0009/0 is now RUNNING
21/10/27 12:11:26 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121126-0009/6 is now RUNNING
21/10/27 12:11:26 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m5.407s
user	2m31.822s
sys	0m19.920s
21/10/27 12:15:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:15:30 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:15:30 INFO ResourceUtils: ==============================================================
21/10/27 12:15:30 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:15:30 INFO ResourceUtils: ==============================================================
21/10/27 12:15:30 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:15:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:15:30 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:15:30 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:15:30 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:15:30 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:15:30 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:15:30 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:15:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:15:30 INFO Utils: Successfully started service 'sparkDriver' on port 35895.
21/10/27 12:15:30 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:15:30 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:15:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:15:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:15:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:15:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-ab77d0bc-2c23-40f9-92af-0520b61e34dd
21/10/27 12:15:30 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:15:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:15:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:15:31 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:15:31 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:35895/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635329730089
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:15:31 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 59 ms (0 ms spent in bootstraps)
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027121531-0010
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121531-0010/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121531-0010/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121531-0010/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121531-0010/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121531-0010/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121531-0010/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121531-0010/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121531-0010/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121531-0010/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121531-0010/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121531-0010/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:15:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35760.
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121531-0010/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:15:31 INFO NettyBlockTransferService: Server created on node054.ib.cluster:35760
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121531-0010/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:15:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121531-0010/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:15:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 35760, None)
21/10/27 12:15:31 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:35760 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 35760, None)
21/10/27 12:15:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 35760, None)
21/10/27 12:15:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 35760, None)
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121531-0010/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121531-0010/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121531-0010/0 is now RUNNING
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121531-0010/1 is now RUNNING
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121531-0010/5 is now RUNNING
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121531-0010/4 is now RUNNING
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121531-0010/2 is now RUNNING
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121531-0010/3 is now RUNNING
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121531-0010/6 is now RUNNING
21/10/27 12:15:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121531-0010/7 is now RUNNING
21/10/27 12:15:31 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	3m57.990s
user	2m31.415s
sys	0m20.072s
21/10/27 12:19:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:19:27 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:19:27 INFO ResourceUtils: ==============================================================
21/10/27 12:19:27 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:19:27 INFO ResourceUtils: ==============================================================
21/10/27 12:19:27 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:19:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:19:28 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:19:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:19:28 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:19:28 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:19:28 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:19:28 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:19:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:19:28 INFO Utils: Successfully started service 'sparkDriver' on port 34898.
21/10/27 12:19:28 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:19:28 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:19:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:19:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:19:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:19:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a1f839fb-db79-44e7-804a-88033981906b
21/10/27 12:19:28 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:19:28 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:19:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:19:28 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:19:28 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:34898/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635329967917
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:19:29 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 36 ms (0 ms spent in bootstraps)
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027121929-0011
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121929-0011/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121929-0011/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121929-0011/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121929-0011/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121929-0011/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121929-0011/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:19:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39337.
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121929-0011/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:19:29 INFO NettyBlockTransferService: Server created on node054.ib.cluster:39337
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121929-0011/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121929-0011/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121929-0011/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121929-0011/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:19:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121929-0011/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121929-0011/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121929-0011/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027121929-0011/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027121929-0011/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:19:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 39337, None)
21/10/27 12:19:29 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:39337 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 39337, None)
21/10/27 12:19:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 39337, None)
21/10/27 12:19:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 39337, None)
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121929-0011/0 is now RUNNING
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121929-0011/1 is now RUNNING
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121929-0011/4 is now RUNNING
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121929-0011/5 is now RUNNING
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121929-0011/2 is now RUNNING
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121929-0011/6 is now RUNNING
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121929-0011/7 is now RUNNING
21/10/27 12:19:29 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027121929-0011/3 is now RUNNING
21/10/27 12:19:29 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	3m54.730s
user	2m33.445s
sys	0m19.544s
21/10/27 12:23:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:23:22 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:23:22 INFO ResourceUtils: ==============================================================
21/10/27 12:23:22 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:23:22 INFO ResourceUtils: ==============================================================
21/10/27 12:23:22 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:23:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:23:22 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:23:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:23:22 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:23:22 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:23:22 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:23:22 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:23:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:23:23 INFO Utils: Successfully started service 'sparkDriver' on port 43666.
21/10/27 12:23:23 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:23:23 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:23:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:23:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:23:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:23:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e6c62513-a1e9-42d4-8e98-8c01f99019d4
21/10/27 12:23:23 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:23:23 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:23:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:23:23 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:23:23 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:43666/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635330202767
21/10/27 12:23:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:23:23 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 60 ms (0 ms spent in bootstraps)
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027122324-0012
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122324-0012/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122324-0012/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122324-0012/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122324-0012/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122324-0012/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122324-0012/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122324-0012/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122324-0012/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122324-0012/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122324-0012/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122324-0012/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122324-0012/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122324-0012/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:23:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39544.
21/10/27 12:23:24 INFO NettyBlockTransferService: Server created on node054.ib.cluster:39544
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122324-0012/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122324-0012/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122324-0012/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:23:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:23:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 39544, None)
21/10/27 12:23:24 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:39544 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 39544, None)
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122324-0012/4 is now RUNNING
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122324-0012/1 is now RUNNING
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122324-0012/3 is now RUNNING
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122324-0012/2 is now RUNNING
21/10/27 12:23:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 39544, None)
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122324-0012/6 is now RUNNING
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122324-0012/5 is now RUNNING
21/10/27 12:23:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 39544, None)
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122324-0012/7 is now RUNNING
21/10/27 12:23:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122324-0012/0 is now RUNNING
21/10/27 12:23:24 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m0.201s
user	2m37.444s
sys	0m19.541s
21/10/27 12:27:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:27:22 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:27:22 INFO ResourceUtils: ==============================================================
21/10/27 12:27:22 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:27:22 INFO ResourceUtils: ==============================================================
21/10/27 12:27:22 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:27:22 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:27:22 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:27:22 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:27:22 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:27:22 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:27:22 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:27:22 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:27:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:27:23 INFO Utils: Successfully started service 'sparkDriver' on port 40155.
21/10/27 12:27:23 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:27:23 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:27:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:27:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:27:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:27:23 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-cda2bdf0-84d2-48d1-8998-b570cf7bf8e4
21/10/27 12:27:23 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:27:23 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:27:23 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:27:23 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:27:23 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:40155/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635330442806
21/10/27 12:27:23 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:27:23 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 59 ms (0 ms spent in bootstraps)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027122724-0013
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122724-0013/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122724-0013/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122724-0013/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122724-0013/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:27:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45729.
21/10/27 12:27:24 INFO NettyBlockTransferService: Server created on node054.ib.cluster:45729
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122724-0013/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122724-0013/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:27:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122724-0013/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122724-0013/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122724-0013/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122724-0013/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122724-0013/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122724-0013/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122724-0013/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122724-0013/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027122724-0013/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:27:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 45729, None)
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027122724-0013/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:27:24 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:45729 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 45729, None)
21/10/27 12:27:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 45729, None)
21/10/27 12:27:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 45729, None)
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122724-0013/1 is now RUNNING
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122724-0013/4 is now RUNNING
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122724-0013/0 is now RUNNING
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122724-0013/5 is now RUNNING
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122724-0013/7 is now RUNNING
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122724-0013/2 is now RUNNING
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122724-0013/6 is now RUNNING
21/10/27 12:27:24 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027122724-0013/3 is now RUNNING
21/10/27 12:27:24 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m3.803s
user	2m38.307s
sys	0m19.498s
21/10/27 12:31:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:31:26 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:31:26 INFO ResourceUtils: ==============================================================
21/10/27 12:31:26 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:31:26 INFO ResourceUtils: ==============================================================
21/10/27 12:31:26 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:31:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:31:26 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:31:26 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:31:26 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:31:26 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:31:26 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:31:26 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:31:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:31:27 INFO Utils: Successfully started service 'sparkDriver' on port 46178.
21/10/27 12:31:27 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:31:27 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:31:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:31:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:31:27 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:31:27 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7a7fd36c-b5a2-48fd-89e1-2ca87ae7ca9d
21/10/27 12:31:27 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:31:27 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:31:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:31:27 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:31:27 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:46178/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635330686696
21/10/27 12:31:27 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:31:27 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 58 ms (0 ms spent in bootstraps)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027123128-0014
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123128-0014/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123128-0014/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123128-0014/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123128-0014/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123128-0014/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123128-0014/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123128-0014/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123128-0014/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123128-0014/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123128-0014/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123128-0014/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123128-0014/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123128-0014/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123128-0014/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:31:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36933.
21/10/27 12:31:28 INFO NettyBlockTransferService: Server created on node054.ib.cluster:36933
21/10/27 12:31:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123128-0014/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123128-0014/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123128-0014/1 is now RUNNING
21/10/27 12:31:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 36933, None)
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123128-0014/4 is now RUNNING
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123128-0014/7 is now RUNNING
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123128-0014/0 is now RUNNING
21/10/27 12:31:28 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:36933 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 36933, None)
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123128-0014/3 is now RUNNING
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123128-0014/5 is now RUNNING
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123128-0014/6 is now RUNNING
21/10/27 12:31:28 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123128-0014/2 is now RUNNING
21/10/27 12:31:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 36933, None)
21/10/27 12:31:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 36933, None)
21/10/27 12:31:28 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m4.797s
user	2m23.481s
sys	0m19.702s
21/10/27 12:35:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:35:31 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:35:31 INFO ResourceUtils: ==============================================================
21/10/27 12:35:31 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:35:31 INFO ResourceUtils: ==============================================================
21/10/27 12:35:31 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:35:31 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:35:31 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:35:31 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:35:31 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:35:31 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:35:31 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:35:31 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:35:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:35:31 INFO Utils: Successfully started service 'sparkDriver' on port 35360.
21/10/27 12:35:32 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:35:32 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:35:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:35:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:35:32 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:35:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3d5ba753-14a3-4e61-9f14-b71ad14eab2d
21/10/27 12:35:32 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:35:32 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:35:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:35:32 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:35:32 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:35360/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635330931518
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:35:32 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 37 ms (0 ms spent in bootstraps)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027123532-0015
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123532-0015/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123532-0015/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123532-0015/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123532-0015/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123532-0015/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123532-0015/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123532-0015/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123532-0015/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123532-0015/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123532-0015/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123532-0015/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123532-0015/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123532-0015/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123532-0015/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:35:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37736.
21/10/27 12:35:32 INFO NettyBlockTransferService: Server created on node054.ib.cluster:37736
21/10/27 12:35:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123532-0015/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:35:32 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123532-0015/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:35:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 37736, None)
21/10/27 12:35:32 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:37736 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 37736, None)
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123532-0015/3 is now RUNNING
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123532-0015/4 is now RUNNING
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123532-0015/1 is now RUNNING
21/10/27 12:35:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 37736, None)
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123532-0015/5 is now RUNNING
21/10/27 12:35:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 37736, None)
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123532-0015/2 is now RUNNING
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123532-0015/0 is now RUNNING
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123532-0015/7 is now RUNNING
21/10/27 12:35:32 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123532-0015/6 is now RUNNING
21/10/27 12:35:33 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	3m58.952s
user	2m35.575s
sys	0m19.527s
21/10/27 12:39:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:39:30 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:39:30 INFO ResourceUtils: ==============================================================
21/10/27 12:39:30 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:39:30 INFO ResourceUtils: ==============================================================
21/10/27 12:39:30 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:39:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:39:30 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:39:30 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:39:30 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:39:30 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:39:30 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:39:30 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:39:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:39:30 INFO Utils: Successfully started service 'sparkDriver' on port 37528.
21/10/27 12:39:31 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:39:31 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:39:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:39:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:39:31 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:39:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-2a6fbcb8-cbb7-42d4-95f1-51fde6a97640
21/10/27 12:39:31 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:39:31 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:39:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:39:31 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:39:31 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:37528/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635331170435
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:39:31 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 59 ms (0 ms spent in bootstraps)
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027123931-0016
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123931-0016/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123931-0016/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123931-0016/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123931-0016/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123931-0016/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123931-0016/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123931-0016/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:39:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42876.
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123931-0016/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:39:31 INFO NettyBlockTransferService: Server created on node054.ib.cluster:42876
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123931-0016/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123931-0016/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123931-0016/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123931-0016/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:39:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123931-0016/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123931-0016/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027123931-0016/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:39:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027123931-0016/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:39:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 42876, None)
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123931-0016/4 is now RUNNING
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123931-0016/7 is now RUNNING
21/10/27 12:39:31 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:42876 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 42876, None)
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123931-0016/6 is now RUNNING
21/10/27 12:39:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 42876, None)
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123931-0016/2 is now RUNNING
21/10/27 12:39:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 42876, None)
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123931-0016/1 is now RUNNING
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123931-0016/5 is now RUNNING
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123931-0016/3 is now RUNNING
21/10/27 12:39:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027123931-0016/0 is now RUNNING
21/10/27 12:39:32 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m2.477s
user	2m38.018s
sys	0m19.470s
21/10/27 12:43:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:43:33 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:43:33 INFO ResourceUtils: ==============================================================
21/10/27 12:43:33 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:43:33 INFO ResourceUtils: ==============================================================
21/10/27 12:43:33 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:43:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:43:33 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:43:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:43:33 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:43:33 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:43:33 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:43:33 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:43:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:43:33 INFO Utils: Successfully started service 'sparkDriver' on port 40733.
21/10/27 12:43:33 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:43:33 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:43:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:43:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:43:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:43:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c1c75934-114a-46fd-a197-6ca44edbe827
21/10/27 12:43:33 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:43:33 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:43:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:43:33 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:43:33 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:40733/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635331412992
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:43:34 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 51 ms (0 ms spent in bootstraps)
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027124334-0017
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124334-0017/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124334-0017/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124334-0017/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124334-0017/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124334-0017/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124334-0017/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124334-0017/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124334-0017/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124334-0017/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124334-0017/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124334-0017/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:43:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35495.
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124334-0017/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:43:34 INFO NettyBlockTransferService: Server created on node054.ib.cluster:35495
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124334-0017/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124334-0017/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:43:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124334-0017/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124334-0017/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:43:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 35495, None)
21/10/27 12:43:34 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:35495 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 35495, None)
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124334-0017/4 is now RUNNING
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124334-0017/3 is now RUNNING
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124334-0017/7 is now RUNNING
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124334-0017/6 is now RUNNING
21/10/27 12:43:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 35495, None)
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124334-0017/2 is now RUNNING
21/10/27 12:43:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 35495, None)
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124334-0017/5 is now RUNNING
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124334-0017/0 is now RUNNING
21/10/27 12:43:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124334-0017/1 is now RUNNING
21/10/27 12:43:34 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m0.199s
user	2m37.383s
sys	0m19.366s
21/10/27 12:47:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:47:33 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:47:33 INFO ResourceUtils: ==============================================================
21/10/27 12:47:33 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:47:33 INFO ResourceUtils: ==============================================================
21/10/27 12:47:33 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:47:33 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:47:33 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:47:33 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:47:33 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:47:33 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:47:33 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:47:33 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:47:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:47:33 INFO Utils: Successfully started service 'sparkDriver' on port 40825.
21/10/27 12:47:33 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:47:33 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:47:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:47:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:47:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:47:33 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-9244aa8d-d1e3-43fa-8843-7e883c720fa6
21/10/27 12:47:33 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:47:33 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:47:34 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:47:34 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:47:34 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:40825/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635331653256
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:47:34 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 45 ms (0 ms spent in bootstraps)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027124734-0018
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124734-0018/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124734-0018/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124734-0018/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124734-0018/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124734-0018/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124734-0018/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124734-0018/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124734-0018/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124734-0018/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124734-0018/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124734-0018/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124734-0018/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124734-0018/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124734-0018/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:47:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43061.
21/10/27 12:47:34 INFO NettyBlockTransferService: Server created on node054.ib.cluster:43061
21/10/27 12:47:34 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027124734-0018/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027124734-0018/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:47:34 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 43061, None)
21/10/27 12:47:34 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:43061 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 43061, None)
21/10/27 12:47:34 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 43061, None)
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124734-0018/1 is now RUNNING
21/10/27 12:47:34 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 43061, None)
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124734-0018/5 is now RUNNING
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124734-0018/3 is now RUNNING
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124734-0018/4 is now RUNNING
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124734-0018/0 is now RUNNING
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124734-0018/7 is now RUNNING
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124734-0018/6 is now RUNNING
21/10/27 12:47:34 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027124734-0018/2 is now RUNNING
21/10/27 12:47:34 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
21/10/27 12:51:28 ERROR TransportResponseHandler: Still have 1 requests outstanding when connection from /10.149.0.61:42046 is closed

real	3m57.052s
user	2m26.158s
sys	0m19.438s
21/10/27 12:51:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:51:30 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:51:30 INFO ResourceUtils: ==============================================================
21/10/27 12:51:30 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:51:30 INFO ResourceUtils: ==============================================================
21/10/27 12:51:30 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:51:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:51:30 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:51:30 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:51:30 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:51:30 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:51:30 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:51:30 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:51:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:51:30 INFO Utils: Successfully started service 'sparkDriver' on port 39295.
21/10/27 12:51:30 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:51:30 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:51:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:51:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:51:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:51:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-c7a3e0d9-69ba-4545-8b1d-9dc63f85d768
21/10/27 12:51:30 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:51:30 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:51:31 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:51:31 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:51:31 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:39295/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635331890237
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:51:31 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 47 ms (0 ms spent in bootstraps)
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027125131-0019
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125131-0019/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125131-0019/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125131-0019/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125131-0019/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125131-0019/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125131-0019/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125131-0019/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125131-0019/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125131-0019/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125131-0019/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125131-0019/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125131-0019/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125131-0019/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125131-0019/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:51:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36954.
21/10/27 12:51:31 INFO NettyBlockTransferService: Server created on node054.ib.cluster:36954
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125131-0019/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:51:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125131-0019/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:51:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 36954, None)
21/10/27 12:51:31 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:36954 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 36954, None)
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125131-0019/0 is now RUNNING
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125131-0019/3 is now RUNNING
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125131-0019/6 is now RUNNING
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125131-0019/2 is now RUNNING
21/10/27 12:51:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 36954, None)
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125131-0019/1 is now RUNNING
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125131-0019/7 is now RUNNING
21/10/27 12:51:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 36954, None)
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125131-0019/5 is now RUNNING
21/10/27 12:51:31 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125131-0019/4 is now RUNNING
21/10/27 12:51:31 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	3m56.253s
user	2m24.939s
sys	0m19.898s
21/10/27 12:55:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:55:26 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:55:26 INFO ResourceUtils: ==============================================================
21/10/27 12:55:26 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:55:26 INFO ResourceUtils: ==============================================================
21/10/27 12:55:26 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:55:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:55:26 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:55:26 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:55:26 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:55:26 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:55:26 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:55:26 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:55:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:55:26 INFO Utils: Successfully started service 'sparkDriver' on port 39768.
21/10/27 12:55:26 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:55:26 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:55:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:55:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:55:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:55:26 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-5adb622d-d9d9-4693-8ca9-7761f0913f29
21/10/27 12:55:26 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:55:26 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:55:27 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:55:27 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:55:27 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:39768/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635332126286
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:55:27 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 57 ms (0 ms spent in bootstraps)
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027125527-0020
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125527-0020/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125527-0020/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125527-0020/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125527-0020/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125527-0020/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125527-0020/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125527-0020/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125527-0020/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125527-0020/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:55:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33879.
21/10/27 12:55:27 INFO NettyBlockTransferService: Server created on node054.ib.cluster:33879
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125527-0020/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125527-0020/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125527-0020/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125527-0020/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:55:27 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125527-0020/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125527-0020/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125527-0020/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:55:27 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 33879, None)
21/10/27 12:55:27 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:33879 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 33879, None)
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125527-0020/1 is now RUNNING
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125527-0020/0 is now RUNNING
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125527-0020/2 is now RUNNING
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125527-0020/4 is now RUNNING
21/10/27 12:55:27 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 33879, None)
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125527-0020/6 is now RUNNING
21/10/27 12:55:27 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 33879, None)
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125527-0020/7 is now RUNNING
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125527-0020/5 is now RUNNING
21/10/27 12:55:27 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125527-0020/3 is now RUNNING
21/10/27 12:55:27 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m2.830s
user	2m35.519s
sys	0m19.552s
21/10/27 12:59:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 12:59:29 INFO SparkContext: Running Spark version 3.2.0
21/10/27 12:59:29 INFO ResourceUtils: ==============================================================
21/10/27 12:59:29 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 12:59:29 INFO ResourceUtils: ==============================================================
21/10/27 12:59:29 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 12:59:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 12:59:29 INFO ResourceProfile: Limiting resource is cpu
21/10/27 12:59:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 12:59:29 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 12:59:29 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 12:59:29 INFO SecurityManager: Changing view acls groups to: 
21/10/27 12:59:29 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 12:59:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 12:59:29 INFO Utils: Successfully started service 'sparkDriver' on port 34053.
21/10/27 12:59:29 INFO SparkEnv: Registering MapOutputTracker
21/10/27 12:59:29 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 12:59:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 12:59:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 12:59:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 12:59:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-866a3ef3-2e88-4a9f-9c68-2f7a14b9cb3d
21/10/27 12:59:29 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 12:59:29 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 12:59:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 12:59:30 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 12:59:30 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:34053/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635332369289
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 12:59:30 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 48 ms (0 ms spent in bootstraps)
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027125930-0021
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125930-0021/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125930-0021/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125930-0021/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125930-0021/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125930-0021/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125930-0021/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125930-0021/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 12:59:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33568.
21/10/27 12:59:30 INFO NettyBlockTransferService: Server created on node054.ib.cluster:33568
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125930-0021/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125930-0021/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125930-0021/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125930-0021/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 12:59:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125930-0021/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125930-0021/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125930-0021/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027125930-0021/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027125930-0021/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 12:59:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 33568, None)
21/10/27 12:59:30 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:33568 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 33568, None)
21/10/27 12:59:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 33568, None)
21/10/27 12:59:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 33568, None)
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125930-0021/4 is now RUNNING
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125930-0021/2 is now RUNNING
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125930-0021/0 is now RUNNING
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125930-0021/7 is now RUNNING
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125930-0021/1 is now RUNNING
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125930-0021/3 is now RUNNING
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125930-0021/5 is now RUNNING
21/10/27 12:59:30 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027125930-0021/6 is now RUNNING
21/10/27 12:59:30 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m12.566s
user	2m31.116s
sys	0m20.225s
21/10/27 13:03:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 13:03:41 INFO SparkContext: Running Spark version 3.2.0
21/10/27 13:03:41 INFO ResourceUtils: ==============================================================
21/10/27 13:03:41 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 13:03:41 INFO ResourceUtils: ==============================================================
21/10/27 13:03:41 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 13:03:41 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 13:03:41 INFO ResourceProfile: Limiting resource is cpu
21/10/27 13:03:41 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 13:03:42 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 13:03:42 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 13:03:42 INFO SecurityManager: Changing view acls groups to: 
21/10/27 13:03:42 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 13:03:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 13:03:42 INFO Utils: Successfully started service 'sparkDriver' on port 37855.
21/10/27 13:03:42 INFO SparkEnv: Registering MapOutputTracker
21/10/27 13:03:42 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 13:03:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 13:03:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 13:03:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 13:03:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-71420d04-9ee0-432a-b3ec-edf43be2eb0e
21/10/27 13:03:42 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 13:03:42 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 13:03:42 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 13:03:42 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 13:03:42 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:37855/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635332621892
21/10/27 13:03:42 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 13:03:43 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 55 ms (0 ms spent in bootstraps)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027130343-0022
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130343-0022/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130343-0022/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130343-0022/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130343-0022/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130343-0022/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130343-0022/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130343-0022/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130343-0022/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130343-0022/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130343-0022/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130343-0022/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130343-0022/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130343-0022/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130343-0022/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 13:03:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43324.
21/10/27 13:03:43 INFO NettyBlockTransferService: Server created on node054.ib.cluster:43324
21/10/27 13:03:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130343-0022/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130343-0022/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 13:03:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 43324, None)
21/10/27 13:03:43 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:43324 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 43324, None)
21/10/27 13:03:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 43324, None)
21/10/27 13:03:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 43324, None)
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130343-0022/6 is now RUNNING
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130343-0022/0 is now RUNNING
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130343-0022/2 is now RUNNING
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130343-0022/5 is now RUNNING
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130343-0022/7 is now RUNNING
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130343-0022/4 is now RUNNING
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130343-0022/1 is now RUNNING
21/10/27 13:03:43 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130343-0022/3 is now RUNNING
21/10/27 13:03:43 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	3m55.427s
user	2m30.246s
sys	0m19.716s
21/10/27 13:07:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 13:07:37 INFO SparkContext: Running Spark version 3.2.0
21/10/27 13:07:37 INFO ResourceUtils: ==============================================================
21/10/27 13:07:37 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 13:07:37 INFO ResourceUtils: ==============================================================
21/10/27 13:07:37 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 13:07:37 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 13:07:37 INFO ResourceProfile: Limiting resource is cpu
21/10/27 13:07:37 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 13:07:37 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 13:07:37 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 13:07:37 INFO SecurityManager: Changing view acls groups to: 
21/10/27 13:07:37 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 13:07:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 13:07:37 INFO Utils: Successfully started service 'sparkDriver' on port 41734.
21/10/27 13:07:37 INFO SparkEnv: Registering MapOutputTracker
21/10/27 13:07:38 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 13:07:38 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 13:07:38 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 13:07:38 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 13:07:38 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7ad50aa5-beb1-4af7-850c-d7f8a840ccb8
21/10/27 13:07:38 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 13:07:38 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 13:07:38 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 13:07:38 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 13:07:38 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:41734/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635332857478
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 13:07:38 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 61 ms (0 ms spent in bootstraps)
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027130738-0023
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130738-0023/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130738-0023/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130738-0023/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130738-0023/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130738-0023/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130738-0023/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 13:07:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36254.
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130738-0023/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 13:07:38 INFO NettyBlockTransferService: Server created on node054.ib.cluster:36254
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130738-0023/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130738-0023/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130738-0023/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 13:07:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130738-0023/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130738-0023/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130738-0023/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130738-0023/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027130738-0023/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 13:07:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 36254, None)
21/10/27 13:07:38 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027130738-0023/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 13:07:38 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:36254 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 36254, None)
21/10/27 13:07:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 36254, None)
21/10/27 13:07:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 36254, None)
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130738-0023/0 is now RUNNING
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130738-0023/1 is now RUNNING
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130738-0023/4 is now RUNNING
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130738-0023/5 is now RUNNING
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130738-0023/7 is now RUNNING
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130738-0023/2 is now RUNNING
21/10/27 13:07:38 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130738-0023/6 is now RUNNING
21/10/27 13:07:39 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027130738-0023/3 is now RUNNING
21/10/27 13:07:39 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m1.396s
user	2m41.168s
sys	0m19.695s
21/10/27 13:11:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
21/10/27 13:11:38 INFO SparkContext: Running Spark version 3.2.0
21/10/27 13:11:38 INFO ResourceUtils: ==============================================================
21/10/27 13:11:38 INFO ResourceUtils: No custom resources configured for spark.driver.
21/10/27 13:11:38 INFO ResourceUtils: ==============================================================
21/10/27 13:11:38 INFO SparkContext: Submitted application: GraphX ConnectedComponents Twitter
21/10/27 13:11:38 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 61440, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
21/10/27 13:11:38 INFO ResourceProfile: Limiting resource is cpu
21/10/27 13:11:38 INFO ResourceProfileManager: Added ResourceProfile id: 0
21/10/27 13:11:38 INFO SecurityManager: Changing view acls to: ddps2001
21/10/27 13:11:38 INFO SecurityManager: Changing modify acls to: ddps2001
21/10/27 13:11:38 INFO SecurityManager: Changing view acls groups to: 
21/10/27 13:11:38 INFO SecurityManager: Changing modify acls groups to: 
21/10/27 13:11:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ddps2001); groups with view permissions: Set(); users  with modify permissions: Set(ddps2001); groups with modify permissions: Set()
21/10/27 13:11:39 INFO Utils: Successfully started service 'sparkDriver' on port 35914.
21/10/27 13:11:39 INFO SparkEnv: Registering MapOutputTracker
21/10/27 13:11:39 INFO SparkEnv: Registering BlockManagerMaster
21/10/27 13:11:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/10/27 13:11:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/10/27 13:11:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/10/27 13:11:39 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d225231f-ceb9-475b-8f41-9815b937a753
21/10/27 13:11:39 INFO MemoryStore: MemoryStore started with capacity 398.7 MiB
21/10/27 13:11:39 INFO SparkEnv: Registering OutputCommitCoordinator
21/10/27 13:11:39 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/10/27 13:11:39 INFO SparkUI: Bound SparkUI to node054.ib.cluster, and started at http://node054.ib.cluster:4040
21/10/27 13:11:39 INFO SparkContext: Added JAR file:/var/scratch/ddps2001/graphx_connected_components_twitter_2010/target/scala-2.12/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar at spark://node054.ib.cluster:35914/jars/graphx_connected_components_twitter_2010_2.12-0.1.0-SNAPSHOT.jar with timestamp 1635333098680
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://10.149.0.54:7077...
21/10/27 13:11:39 INFO TransportClientFactory: Successfully created connection to /10.149.0.54:7077 after 33 ms (0 ms spent in bootstraps)
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20211027131139-0024
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027131139-0024/0 on worker-20211027113459-10.149.0.58-34420 (10.149.0.58:34420) with 32 core(s)
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027131139-0024/0 on hostPort 10.149.0.58:34420 with 32 core(s), 60.0 GiB RAM
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027131139-0024/1 on worker-20211027113458-10.149.0.59-43669 (10.149.0.59:43669) with 32 core(s)
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027131139-0024/1 on hostPort 10.149.0.59:43669 with 32 core(s), 60.0 GiB RAM
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027131139-0024/2 on worker-20211027113459-10.149.0.61-45554 (10.149.0.61:45554) with 32 core(s)
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027131139-0024/2 on hostPort 10.149.0.61:45554 with 32 core(s), 60.0 GiB RAM
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027131139-0024/3 on worker-20211027113458-10.149.0.57-44882 (10.149.0.57:44882) with 32 core(s)
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027131139-0024/3 on hostPort 10.149.0.57:44882 with 32 core(s), 60.0 GiB RAM
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027131139-0024/4 on worker-20211027113459-10.149.0.62-38129 (10.149.0.62:38129) with 32 core(s)
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027131139-0024/4 on hostPort 10.149.0.62:38129 with 32 core(s), 60.0 GiB RAM
21/10/27 13:11:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44025.
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027131139-0024/5 on worker-20211027113459-10.149.0.56-35044 (10.149.0.56:35044) with 32 core(s)
21/10/27 13:11:39 INFO NettyBlockTransferService: Server created on node054.ib.cluster:44025
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027131139-0024/5 on hostPort 10.149.0.56:35044 with 32 core(s), 60.0 GiB RAM
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027131139-0024/6 on worker-20211027113459-10.149.0.55-38255 (10.149.0.55:38255) with 32 core(s)
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027131139-0024/6 on hostPort 10.149.0.55:38255 with 32 core(s), 60.0 GiB RAM
21/10/27 13:11:39 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20211027131139-0024/7 on worker-20211027113459-10.149.0.60-40755 (10.149.0.60:40755) with 32 core(s)
21/10/27 13:11:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/10/27 13:11:39 INFO StandaloneSchedulerBackend: Granted executor ID app-20211027131139-0024/7 on hostPort 10.149.0.60:40755 with 32 core(s), 60.0 GiB RAM
21/10/27 13:11:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, node054.ib.cluster, 44025, None)
21/10/27 13:11:39 INFO BlockManagerMasterEndpoint: Registering block manager node054.ib.cluster:44025 with 398.7 MiB RAM, BlockManagerId(driver, node054.ib.cluster, 44025, None)
21/10/27 13:11:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, node054.ib.cluster, 44025, None)
21/10/27 13:11:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, node054.ib.cluster, 44025, None)
21/10/27 13:11:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027131139-0024/4 is now RUNNING
21/10/27 13:11:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027131139-0024/1 is now RUNNING
21/10/27 13:11:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027131139-0024/5 is now RUNNING
21/10/27 13:11:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027131139-0024/2 is now RUNNING
21/10/27 13:11:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027131139-0024/3 is now RUNNING
21/10/27 13:11:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027131139-0024/7 is now RUNNING
21/10/27 13:11:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027131139-0024/0 is now RUNNING
21/10/27 13:11:40 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20211027131139-0024/6 is now RUNNING
21/10/27 13:11:40 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0

real	4m10.374s
user	2m27.367s
sys	0m20.419s
